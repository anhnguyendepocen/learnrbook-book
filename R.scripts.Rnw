% !Rnw root = appendix.main.Rnw

<<echo=FALSE, cache=FALSE>>=
set_parent('r4p.main.Rnw')
opts_knit$set(concordance=TRUE)
@

\chapter{R Scripts and Programming}\label{chap:R:scripts}
\index{scripts}
\dictum[\href{https://cran.r-project.org/doc/contrib/Lemon-kickstart/}{Kickstarting R}]{An R script is simply a text file containing (almost) the same commands that you would enter on the command line of R.}\vskip2ex

\section{Aims of this chapter}

In my experience, for those who have mainly used graphical user interfaces, understanding why and when scripts can help in communicating a certain data analysis protocol can be revelatory. As soon as a data analysis stops being trivial, describing the steps followed through a system of menus and dialogue boxes becomes extremely tedious.

It is also usually the case that graphical user interfaces tend to be difficult to extend or improve in a way that keeps step-by-step instructions valid across program versions and operating systems.

Many times exactly the same sequence of commands needs to be applied to different data sets, and scripts make both implementation and validation of such a requirement easy.

In this chapter I will walk you through the use of \Rpgrm scripts, starting from a extremely simple script.

\section{What is a script?}\label{sec:script:what:is}
\index{scripts!definition}
We call \textit{script} to a text file that contains (almost) the same commands that you would type at the console prompt. A true script is not for example an MS-Word file where you have pasted or typed some R commands. A script file has the following characteristics.
\begin{itemize}
  \item The script is a text file (ASCII or some other encoding e.g.\ UTF-8 that \Rpgrm uses in your locale).
  \item The file contains valid R statements (including comments) and nothing else.
  \item Comments start at a \code{\#} and end at the end of the line. (True end-of line as coded in the file, the editor may wrap lines or not at the edge of the screen).
  \item The R statements are in the file in the order that they must be executed.
  \item R scripts have file names ending in \texttt{.r} or \texttt{.R}.
\end{itemize}

It is good practice to write scripts so that they are self-contained. To make a script self-contained, one must include calls to \texttt{library()} to load the packages used in addition to all the data-analysis commands. Such scripts can be used to generate the output of the analysis and/or to reproduce an earlier analysis.

<<setup-scripts, include=FALSE, cache=FALSE>>=
show.results <- FALSE
@

\section{How do we use a scrip?}\label{sec:script:using}
\index{scripts!sourcing}

A script can be ``sourced'' using fonction \Rfunction{source()}. If we have a text file called \texttt{my.first.script.r} containing the following text:
\begin{shaded}
\footnotesize
\begin{verbatim}
# this is my first R script
print(3 + 4)
\end{verbatim}
\end{shaded}

And then source this file:

<<evaluate=FALSE>>=
source("my.first.script.r")
@

The results of executing the statements contained in the file will appear in the console. The commands themselves are not shown (the sourced file is not \emph{echoed} to the console) and the results will not be printed unless you include explicit \Rfunction{print()} commands in the script. This applies in many cases also to plots---e.g.\ A figure created with \Rfunction{ggplot()} needs to be printed if we want it to be included in the output when the script is run. Adding a redundant \Rfunction{print()} is harmless.

From within \RStudio, if you have an \Rpgrm script open in the editor, there will be a ``source'' drop box ($\neq$ DropBox) visible from where you can choose ``source'' as described above, or ``source with echo'' for the currently open file.

When a script is \emph{sourced}, the output can be saved to a text file instead of being shown in the console. It is also easy to call \Rpgrm with the script file as argument directly at the command prompt of the operating system.
\begin{shaded}
\footnotesize
\begin{verbatim}
RScript my.first.script.r
\end{verbatim}
\end{shaded}

You can open an operating system's \emph{shell} from the Tools menu in \RStudio, to run this command. The output will be printed to the shell console. If you would like to save the output to a file, use redirection using the operating system's syntax.
\begin{shaded}
\footnotesize
\begin{verbatim}
RScript my.first.script.r > my.output.txt
\end{verbatim}
\end{shaded}

Sourcing is very useful when the script is ready, however, while developing a script, or sometimes when testing things, one usually wants to run (or \emph{execute}) one or a few statements at a time. This can be done using the ``run'' button\footnote{If you use a different IDE or editor with an R mode, the details will vary, but a run command will be usually available.} after either positioning the cursor in the line to be executed, or selecting the text that one would like to run (the selected text can be part of a line, a whole line, or a group of lines, as long as it is syntactically valid). The key-shortcut Ctrl-Enter is equivalent to pressing the ``run'' button in \RStudio.

\section{How to write a script?}\label{sec:script:writing}
\index{scripts!writing}

As with any type of writing various approaches may be preferred by different users. In general, the approach used, or mix of approaches will also depend on how confident you are that the statements will work as expected---you already know the best approach vs.\ you are exploring different alternatives. 
\begin{description}
\item[If one is very familiar with similar problems] One would just create a new text file and write the whole thing in the editor, and then test it. This is rather unusual.
\item[If one if moderately familiar with the problem] One would write the script as above, but testing it, step by step as one is writing it. This is usually what I do.
\item[If one is mostly playing around] Then if one is using \RStudio, one can type statements at the console prompt. As you should know by now, everything you run at the console is saved to the ``History''. In \RStudio the History is displayed in its own pane, and in this pane one can select any previous statement(s) and by pressing a single button copy and paste them to either the console prompt, or the cursor position in the editor pane. In this way one can build a script by copying and pasting from the history to your script file the bits that have worked as you wanted.
\end{description}

\begin{playground}
By now you should be familiar enough with R to be able to write your own script.
\begin{enumerate}
  \item Create a new \Rpgrm script (in \RStudio, from `File' menu, ``+'' button, or by typing ``Ctrl + Shift + N'').
  \item Save the file as \texttt{my.second.script.r}.
  \item Use the editor pane in \RStudio to type some \Rpgrm commands and comments.
  \item \emph{Run} individual commands.
  \item \emph{Source} the whole file.
\end{enumerate}
\end{playground}

\section{The need to be understandable to people}\label{sec:script:readability}
\index{scripts!readability}

When you write a script, it is either because you want to document what you have done or you want re-use it at a later time. In either case, the script itself although still meaningful for the computer could become very obscure to you, and even more to someone seeing it for the first time. This must be avoided by spending time and effort.

How does one achieve an understandable script or program?
\begin{itemize}
  \item Avoid the unusual. People using a certain programming language tend to use some implicit or explicit rules of style\footnote{Style includes \textit{indentation} of statements, \textit{capitalization} of variable and function names.}. As a minimum try to be consistent with yourself.
  \item Use meaningful names for variables, and any other object. What is meaningful depends on the context. Depending on common use a single letter may be more meaningful than a long word. However self explanatory names are better: e.g. using \code{n.rows} and \code{n.cols} is much clearer than using \code{n1} and \code{n2} when dealing with a matrix of data. Probably \code{number.of.rows} and \code{number.of.columns} would make the script verbose, take longer to type without gaining much in return.
  \item How to make the words visible in names: traditionally in R one would use dots to separate the words and use only lower case. Some years ago, it became possible to use underscores. The use of underscores is quite common nowadays because in some contexts it is ``safer'' as in some situations a dot may have a special meaning. What we call ``camel case'' is only infrequently used in R programming but is common in other languages like Pascal. An example of camel case is \code{NumCols}. In some cases it can become a bit confusing as in \code{UVMean} or \code{UvMean}.
\end{itemize}

\begin{playground}
Here is an example of bad style in a script. Read \href{https://google.github.io/styleguide/Rguide.xml}{Google's R Style Guide}\footnote{This is just an example, similar, but not exactly the same style as the style I use myself.}, and edit the code in the chuck below so that it becomes easier to read.

<<eval=FALSE>>=
a <- 2 # height
b <- 4 # length
C <-
    a *
b
C -> variable
      print(
"area: ", variable
)
@
\end{playground}

The points discussed above already help a lot. However, one can go further in achieving the goal of human readability by interspersing explanations and code ``chunks'' and using all the facilities of typesetting, even of formatted maths formulas and equations, within the listing of the script. Furthermore, by including the results of the calculations and the code itself in a typeset report built automatically, we ensure that the results are indeed the result of running the code shown. This greatly contributes to data analysis reproducibility, which is becoming a widespread requirement for any data analysis both in academic research and in industry. It is possible not only to build whole books like this one, but also whole data-based web sites with these tools.

In the realm of programming, this approach is called literate programming\index{literate programming} and was first proposed by Donald Knuth \autocite{Knuth1984a} through his \pgrmname{WEB} system. In the case of \Rpgrm programming the first support of literate programming was through \pkgname{Sweave}, which has been mostly superseded by \pkgname{knitr} \autocite{Xie2013}. This package supports the use of Markdown or \LaTeX\ \autocite{Lamport1994} as markup language for the textual contents, and also can format and add syntax highlighting to code chunks. Markdown\index{Markdown}\index{Bookdown} language has been extended to make it easier to include R code---R Markdown (\url{http://rmarkdown.rstudio.com/}), and in addition suitable for typesetting large and complex documents---Bookdown \autocite{Xie2016}. The use of \pkgname{knitr} is well integrated into the \RStudio IDE.

This is not strictly an R programming subject, as it concerns programming in any language. On the other hand, this is an incredibly important skill to learn, but well described in other books and web sites cited in the previous paragraph. This whole book, including figures, has been generated using \pkgname{knitr} and the source scripts for the book are available through Bitbucket at \url{https://bitbucket.org/aphalo/learnr-book}.

\section{Debugging scripts}\label{sec:script:debug}
\index{scripts!debugging}

The use of the word \emph{bug} to describe a problem in computer hardware and software started in 1946 when a real bug, more precisely a moth, got between the contacts of a relay in an electromechanical computer causing it to malfunction and Grace Hooper described the first computer \emph{bug}. The use of the term bug in engineering predates the use in computer science, and consequently the first use of bug in computing did catch-on easily as it was memorable as it represented an earlier-used metaphor becoming real.

A suitable quotation from a letter written by Thomas Alva Edison 1878 (\autocite{Hughes2004}):
\begin{quote}
  It has been just so in all of my inventions. The first step is an intuition, and comes with a burst, then difficulties arise--this thing gives out and [it is] then that ``Bugs''--as such little faults and difficulties are called--show themselves and months of intense watching, study and labor are requisite before commercial success or failure is certainly reached.
\end{quote}

The quoted paragraph above, makes clear, that only very exceptionally any new design fully succeeds. The same applies to R scripts as well as any other non-trivial piece of computer code. From this it logically follows that testing and de-bugging are fundamental steps in the development of R scripts and packages. Debugging, as an activity, is outside the scope of this book. However, clear programming style and good documentation are indispensable for efficient testing and reuse.

Even for scripts used for analysing a single data set, we need to be confident that the algorithms and their implementation are valid, and able to return correct results. This is true both for scientific reports, expert data-based reports and any data analysis related to assessment of compliance with legislation or regulations. Of course, even in cases when we are not required to demonstrate validity, say for decision making purely internal to a private organization, we will still want to avoid costly mistakes.

The first step in producing reliable computer code is to accept that any code that we write needs to be tested and, if possible, validated. Another important step is to make sure that input is validated within the script and a suitable error produced for bad input (or input values outside the range that can be reliably handled by the script).

If during testing, or during normal use, a wrong value is returned by a calculation, or no value (e.g.\ the script crashes or triggers a fatal error), debugging consists in finding the cause of the problem. The cause can be either a mistake in the implementation of an algorithm, as well as in the algorithm itself. However, many apparent \emph{bugs} are caused by bad or missing handling of special cases like invalid input values, rounding errors, division by zero, etc.\ in which a program crashes instead of elegantly issuing a helpful error message.

Diagnosing the source of bugs is in most cases like detective work. One uses hunches based on common sense and experience to try to locate the lines of code causing the problem. One follows different \emph{leads} until the case is solved. In most cases at the very bottom we rely on some sort of divide and conquer strategy. For example, we may check the value returned by intermediate calculations until we locate the earliest code statement producing a wrong value. Another common case is when some input values trigger a bug. In such cases it is frequently best to start by testing if different ``cases'' of input lead to errors/crashes or not. Boundary input values are usually the telltale ones: e.g.\ for numbers, zero, negative and positive values, very large values, very small values, missing values (\code{NA}), vectors of length zero (\code{numeric()}), etc.

\begin{warningbox}
  \paragraph{Error messages} When debugging keep in mind that in some cases a single bug can lead to a whole cascade of error messages. Do also keep in mind that typing mistakes, originating when code is entered through the keyboard, can break havock in a script: usually there is little correspondence between the number of error messages and the seriousness of the bug triggering them. When several errors are triggered, start by reading the error message printed first, as later errors can be an indirect consequence of earlier ones.
\end{warningbox}

There are special tools, called debuggers, available, and they help enormously. Debuggers allow one to step through the code, executing one statement at a time and at each pause allowing the user to inspect the objects present in the R environment and their values. It is even possible to execute additional statements, say to modify the value of a variable, while execution is paused. An R debugger is available within \RStudio and also through the R console.

At first, when writing your first scripts, you will manage perfectly well, and learn more by running the script one line at a time and when needed temporarily inserting \code{print()} statements to ``look'' at how the value of variables changes at each step. A debugger, allows a lot more control, as one can ``step in'' and ``step out'' of functions definitions, set and unset break points where execution will stop, which is especially useful when developing R packages.

When reproducing the examples in this chapter, do keep this section in mind. In addition, if you get stuck trying to find the cause of a bug, do extend your search both to the most trivial of possible causes, and to the least likely ones (such as a bug in a CRAN package or R itself). Of course, when suspecting a bug in code you have not written, it is wise to very carefully read the documentation, as the ``bug'' may be just in your understanding of what a certain piece of code is expected to do.  Also remember, as discussed on page \pageref{sec:getting:help}, you will find on-line ready-answersed questions to many of your likely problems and doubts. For example Googling for the text of an error message is usually well rewarded. Failing this, you can ask questions at, e.g., StackOverflow (\url{https://stackoverflow.com/}), after searching the site for possible existing answers.

\begin{warningbox}
When installing packages from other sources than CRAN (e.g.\ development versions from Github, Bitbucket or Rforge, or in-house packages) there is no warranty that conflicts will not happen. Packages (and their versions) released through CRAN are regularly checked for inter-compatibility, while packages released through other channels are usually checked against only a few packages.

Conflicts among packages can easily arise, for example when they use the same names for objects or functions. In addition, many packages use functions defined in packages in the R distribution itself or other independently developed packages by importing them. Updates to depended upon packages can ``break'' (make non-functional) the dependent packages or parts of them. The rigorous testing by CRAN detects in most cases such problems when package revisions are submitted, forcing package maintainers to fix problems before distribution through CRAN is possible. However, if you use other repositories, I recommend that you make sure that revised (especially if under development) versions do work with your own script, before their use in ``production'' (important) data analyses.
\end{warningbox}

\section{Functions}\label{sec:script:functions}
\index{functions!defining new}

When writing scripts, or any program, one should avoid repeating blocks of code (groups of statements). The reasons for this are: 1) if the code needs to be changed---e.g.\ to fix a bug or error---, you have to make changes in more than one place in the file, or in more than one file. Sooner or later, some copies will remain unchanged by mistake. This leads to inconsistencies and hard to track bugs; 2) it makes the script file longer, and this makes debugging, commenting, etc. more tedious, and error prone; 3) abstraction and division of a problem into smaller chunks, helps with keeping the code understandable to humans.

How do we avoid repeating bits of code? We write a function containing the statements that we would need to repeat, and then \emph{call} (``use'') the function in their place.

Functions are defined by means of \Rfunction{function()}, and saved like any other object in \Rpgrm by assignment to a variable. In the example below \code{x} and \code{y} are both formal parameters, or names used within the function for objects that will be supplied as ``arguments'' when the function is called. One can think of parameter names as place-holders.

<<fun-00>>=
my.prod <- function(x, y){x * y}
my.prod(4, 3)
@

First\index{functions:arguments} some basic knowledge. In R, arguments are passed by copy. This is something very important to remember. Whatever you do within a function to modify an argument, its value outside the function will remain (almost) always unchanged.

<<fun-01>>=
my.change <- function(x){x <- NA}
a <- 1
my.change(a)
a
@

Any result that needs to be made available outside the function must be returned by the function. If the function \Rfunction{return()} is not explicitly used, the value returned by the last statement \emph{executed} within the body of the function will be returned.

\label{chunck:print:funs}
<<fun-02>>=
print.x.1 <- function(x){print(x)}
print.x.1("test")
print.x.2 <- function(x){print(x); return(x)}
print.x.2("test")
print.x.3 <- function(x){return(x); print(x)}
print.x.3("test")
print.x.4 <- function(x){return(); print(x)}
print.x.4("test")
print.x.5 <- function(x){x}
print.x.4("test")
@

Now we will define a useful function: a function for calculating the standard error of the mean from a numeric vector.

<<fun-1NN>>=
SEM <- function(x){sqrt(var(x) / length(x))}
a <- c(1, 2, 3, -5)
a.na <- c(a, NA)
SEM(x = a)
SEM(a)
SEM(a.na)
@

For example in \code{SEM(a)} we are calling function \Rfunction{SEM()} with \code{a} as argument.

The function we defined above may sometimes give a wrong answer because NAs will be counted by \code{length()}, so we need to remove NAs before calling \code{length()}.

<<fun-1-safe>>=
simple_SEM <- function(x) {
 sqrt(var(x, na.rm=TRUE)/length(na.omit(x)))
}
a <- c(1, 2, 3, -5)
a.na <- c(a, NA)
simple_SEM(x=a)
simple_SEM(a)
simple_SEM(a.na)
@

R does not have a function for standard error, so the function above would be generally useful. If we would like to make this function both safe, and consistent with other R functions, one could define it as follows, allowing the user to provide a second argument which is passed as an argument to \Rfunction{var()}:

<<fun-2>>=
SEM <- function(x, na.rm = FALSE){
  sqrt(var(x, na.rm = na.rm) / length(na.omit(x)))
}
SEM(a)
SEM(a.na)
SEM(a.na, TRUE)
SEM(x = a.na, na.rm = TRUE)
SEM(TRUE, a.na)
SEM(na.rm = TRUE, x = a.na)
@

In this example you can see that functions can have more than one parameter, and that parameters can have default values to be used if no argument is supplied. In addition if the name of the parameter is indicated, then arguments can be supplied in any order, but if parameter names are not supplied, then arguments are assigned to parameters based on their position. Once one parameter name is given, all later arguments need also to be explicitly matched to parameters. Obviously if given by position, then arguments should be supplied explicitly for all parameters at `intermediate' positions.

%We can assign to a variable defined `outside' a function with operator \code{<<-} but the usual recommendation is to avoid its use. This type of effects of calling a function are frequently called `side-effects'.

\begin{playground}
Test the behaviour of functions \code{print.x.1()} and \code{print.x.5()}, as defined on page \pageref{chunck:print:funs}, at the command prompt, and in a script, by writing a script.
The behaviour of one of these functions will be different when the script is source than at the command prompt. Explain why.
\end{playground}

\begin{playground}
Define your own function to calculate the mean in a similar way as \Rfunction{SEM()} was defined above. Hint: function \Rfunction{sum()} could be of help.
\end{playground}

\begin{playground}
Create some additional vectors containing \code{NA}s or not. Use them to test functions \Rfunction{simple\_SEM()} and \Rfunction{SEM()} defined above, and then explain why \code{SEM()} returns always the correct value, even though ``\code{na.omit(x)}'' is non-conditionally (always) applied to \code{x} before calculating its length.
\end{playground}

\begin{explainbox}
\Rpgrm handles evaluation of function arguments differently to many other computer languages. Not only arguments are passed by value, but in addition they are evaluated only at the time of first use in the function body code. This is called \emph{lazy evaluation} and before evaluation arguments remain as \emph{promises}. In many cases this is advantageous by improving computation efficiency. However, if the value of the variable used as argument or in an expression used as argument changes, the value of the variable at the time of evaluation will be used. This is rarely a problem, but being aware of this behaviour is helpful specially when programmatically defining functions. Very rarely, an argument will not the evaluated when it should (e.g.\ because of bugs in packages, or use of ``trickery''). Earlier evaluation can be forced at any time with function \code{force()}.
\end{explainbox}

\section{Objects, classes and methods}\label{sec:script:objects:classes:methods}

An\index{objects}\index{classes}\index{methods} in-depth discussion of object oriented programming in \langname{R} is outside the scope of this book. Several books describe in detail the different class systems available and how to take best advantage of them when developing packages extending R. For the non-programmer user, a basic understanding can be useful, even if he or she do not intend to create new classes. This basic knowledge is what we intend to convey in this section. For an in-depth treatment of the subject please consult the recently published book \citetitle{Wickham2014} \autocite{Wickham2014}.

We start with a quotation form \citetitle{Burns1998} \autocite[][, page 13]{Burns1998}.
\begin{quotation}
The idea of object-oriented programming is simple, but carries a lot of weight.
Here's the whole thing: if you told a group of people ``dress for work'', then
you would expect each to put on clothes appropriate for that individual's job.
Likewise it is possible for S[R] objects to get dressed appropriately depending on
what class of object they are.
\end{quotation}

\langname{R} supports the use of the object oriented programming paradigm, but as a system that has evolved over the years, currently \langname{R} includes different approaches. The still most popular approach is called S3, and a more recent and powerful approach, with slower performance, is called S4. The general idea is that a generic name like ``plot'' can be used as a generic name, and that which specific version of \Rfunction{plot()} is called depends on the arguments of the call. Using computing terms we could say that the generic version of \Rfunction{plot()} dispatches the original call to different specific versions of \Rfunction{plot()} based on the class of the arguments passed. S3 generic functions dispatch, by default, based only on the argument passed to a single parameter, the first one. S4 generic functions can dispatch the call based on the arguments passed to more than one parameter and the structure of the objects of a given class is known to the interpreter. In S3 functions the specializations of a generic are recognized/identified only by their name. And the class of an object by a character string stored as an attribute to the object.

The most basic approach is to create a new class, pre-pending its name to the existing class attribute of an object. This would normally take place within a constructor.

<<explain-object-classes-01>>=
a <- 123
class(a)
class(a) <- c("myclass", class(a))
class(a)
@

Now we create a print method specific to \code{"myclass"} objects.
<<explain-object-classes-02>>=
print.myclass <- function(x) {
    sprintf("[myclass] %.g4", x)
}
@

Once a specialized method exists for a class, it will be used for objects of this class.

<<explain-object-classes-03>>=
print(a)
print(as.numeric(a))
@

The S3 class system is ``lightweight'' in that it adds very little additional computation load, but it is rather fragile in that most of the responsibility about consistency and correctness of the design---e.g.\ not messing up dispatch by redefining functions or loading a package exporting functions with the same name, etc.-- is not checked by the R interpreter.

Defining a new S3 generic is also quite simple. A generic method and a default method need to be created.

<<explain-object-classes-04>>=
my_print <- function (x, ...) {
   UseMethod("my_print", x)
 }

my_print.default <- function(x, ...) {
   print(class(x))
   print(x, ...)
}
@

<<explain-object-classes-05>>=
my_print(123)
my_print("abc")
@

Up to now, \Rfunction{my\_print()}, has no specialization. We now write one for data frames.

<<explain-object-classes-06>>=
my_print.data.frame <- function(x, rows = 1:5, ...) {
   print(x[rows, ], ...)
   invisible(x)
}
@

We add the second statement so that the function returns invisibly the whole data frame, rather than the lines printed. We now do a quick test of the function.

<<explain-object-classes-07>>=
my_print(cars)
my_print(cars, 8:10)
my_print(cars, TRUE)
b <- my_print(cars)
b
@

\begin{playground}
1) What would be the most concise way of defining a \code{my\_print()} specialization for \code{matrix}? Write one, and test it.
2) How would you modify the code of your \code{my\_print.matrix()} so that also columns to print can be selected?
\end{playground}

\section{Control of execution flow}\label{sec:script:flow:control}
\index{control of execution flow}
We call control of execution statements those that allow the execution of sections of code when a certain dynamically computed condition is \code{TRUE}. Some of the control of execution flow statements, function like \emph{ON-OFF switches} for program statements. Others, allow statements to executed repeatedly while or until a condition is met, or until all members of a list or a vector are processed.

\subsection{Conditional execution}
\index{conditional execution}
\subsubsection{Non-vectorized}

\Rpgrm has two types of \emph{if}\index{if} statements, non-vectorized and vectorized. We will start with the non-vectorized one, which is similar to what is available in most other computer programming languages.

Before this we need to explain compound statements. Individual statements can be grouped into compound statements by enclosed them in curly braces.

<<if-1>>=
print("A")
{
  print("B")
  print("C")
}
@

The grouping of the last two statements above is of no consequence by itself, but grouping becomes useful when used together with `control' constructs. The \code{if} construct controls the execution of one statement, however, this statement can be a compound statement of almost any length or complexity. Play with the code below by changing the value assigned to variable \code{printing}, including \code{NA}, and \code{logical(0)}.

<<if-2>>=
printing <- TRUE
if (printing) {
  print("A")
  print("B")
}
@

The condition passed as argument to \code{if} enclosed in parentheses, can be anything yielding a \Rclass{logical} vector, however, as this condition is not vectorized, only the first element will be used. Play with this example by changing the value assigned to \code{a}.

<<if-3>>=
a <- 10.0
if (a < 0.0) print("'a' is negative") else print("'a' is not negative")
print("This is always printed")
@

As you can see above the statement immediately following \code{else} is executed if the condition is false. Later statements are executed independently of the condition.

Do you still remember the rules about continuation lines?

<<auxiliary, echo=FALSE, eval=TRUE>>=
show.results <- TRUE
if (show.results) eval.if.4 <- c(1:4) else eval.if.4 <- FALSE
eval.if.4
show.results <- FALSE
if (show.results) eval.if.4 <- c(1:4) else eval.if.4 <- FALSE
eval.if.4
@

<<if-4>>=
# 1
a <- 1
if (a < 0.0)
  print("'a' is negative") else
    print("'a' is not negative")
@

Why does the statement below (not evaluated here) trigger an error?

<<if-4a, eval=FALSE>>=
# 2 (not evaluated here)
if (a < 0.0) print("'a' is negative")
else print("'a' is not negative")
@

\begin{playground}
Play with the use conditional execution, with both simple and compound statements, and also think how to combine \code{if} and \code{else} to select among more than two options.
\end{playground}

\begin{playground}
Study the conversion rules between \Rclass{numeric} and \Rclass{logical} values, run each of the statements below, and explain the output based on how type conversions are interpreted, remembering the difference between \emph{floating-point numbers} as implemented in computers and \emph{real numbers} ($\mathbb{R}$) as defined in mathematics:

<<eval=FALSE>>=
if (0) print("hello")
if (-1) print("hello")
if (0.01) print("hello")
if (1e-300) print("hello")
if (1e-323) print("hello")
if (1e-324) print("hello")
if (1e-500) print("hello")
if (as.logical("true")) print("hello")
if (as.logical(as.numeric("1"))) print("hello")
if (as.logical("1")) print("hello")
if ("1") print("hello")
@

\end{playground}

There is in \langname{R} a \Rfunction{switch()} statement, that we describe here, which can be used to select among ``cases'', or several alternative statements, based on an expression evaluating to a number or a character string. The switch statement returns a value, the value returned by the code corresponding to the matching switch value, or the default if there is no match, and a default has been included in the code. Both character values or numeric values can used.

<<>>=
my.object <- "two"
b <- switch(my.object,
            one = 1,
            two = 1 / 2,
            three = 1 / 4,
            0
)
b
@

\begin{playground}
    Do play with the use of the switch statement. Look at the documentation for \code{switch()} using \code{help(switch)} and study the examples at the end of the help page.
\end{playground}

\subsubsection{Vectorized}
\index{vectorized if-else}
Vectorized \emph{if} is a peculiarity of the R language, but very useful for writing concise code that executes a lot faster than logically equivalent but not vectorized code.
Vectorized conditional execution is coded by means of \emph{function} \Rfunction{ifelse()} (written as a single word). This function takes three arguments: a \Rclass{logical} vector (\code{test}), a result vector for TRUE (\code{yes}), a result vector for FALSE (\code{no}). All three can be any R construct giving the necessary argument as their return value. In the case of vectors passed as arguments to parameters \code{yes} and \code{no}, recycling will take place if they are shorter than the logical vector passed as argument to \code{test}. No recycling ever applies to \code{test}, even if  \code{yes} and/or \code{no} are longer than \code{test}. It is customary to pass arguments to \code{ifelse} by position. We give a first example with named arguments to clarify the use of the function.

<<ifelse-0>>=
my.test <- c(TRUE, FALSE, TRUE, TRUE)
ifelse(test = my.test, yes = 1, no = -1)
@

In practice, the most common idiom is to have as argument passed to \code{test} the result of a comparison calculated on-the-fly. In the first example we compute the absolute values for a vector, equivalent to that returned by R function \code{abs()}.

<<ifelse-0a>>=
nums <- -3:+3
ifelse(nums < 0, -nums, nums)
@

Some additional examples, with a few surprises.

<<ifelse-1>>=
a <- 1:10
ifelse(a > 5, 1, -1)
ifelse(a > 5, a + 1, a - 1)
ifelse(any(a > 5), a + 1, a - 1) # tricky
ifelse(logical(0), a + 1, a - 1) # even more tricky
ifelse(NA, a + 1, a - 1) # as expected
@

\begin{warningbox}
In the case of \Rfunction{ifelse()}, the length of the returned value is determined by the length of the logical vector passed as argument to its first formal parameter (named \code{test})! A frequent mistake is to use a condition that returns a \code{logical} of length one, expecting that it will be recycled because arguments passed to the other formal parameters (named \code{yes} and \code{no}) are longer. However, no recycling will take place, resulting in a returned value of length one, with the remaining of the vectors being discarded. Do try this by yourself, using logical vectors of different lengths. You can start with the examples below, making sure you understand why the returned values are what they are.

<<>>=
ifelse(TRUE, 1:5, -5:-1)
ifelse(FALSE, 1:5, -5:-1)
ifelse(c(TRUE, FALSE), 1:5, -5:-1)
ifelse(c(FALSE, TRUE), 1:5, -5:-1)
ifelse(c(FALSE, TRUE), 1:5, 0)
@
\end{warningbox}

\begin{playground}
Try to understand what is going on in the previous examples. Create your own examples to test how \Rfunction{ifelse()} works. In other words, play with the code until you fully understand how \code{ifelse} works.
\end{playground}

\begin{playground}
Write, using \Rfunction{ifelse()}, a single statement to combine numbers from the two vectors \code{a} and \code{b} into a result vector \code{d}, based on whether the corresponding value in vector \code{c} is the character \code{"a"} or \code{"b"}. Then print vector \code{d} to make the result visible.

<<ifelse-2>>=
a <- -10:-1
b <- +1:10
c <- c(rep("a", 5), rep("b", 5))
# your code
@

If you do not understand how the three vectors are built, or you cannot guess the values they contain by reading the code, print them, and play with the arguments, until you have clear what each parameter does. Also use \code{help()} to access the documentation.
\end{playground}

\subsection{Why using vectorized functions and operators is important}
\index{vectorization}\index{recycling of arguments}
If you have written programs in other languages, it would feel to you natural to use loops (for, repeat while, repeat until) for many of the things for which we have been using vectorization. When using the \langname{R} language it is best to use vectorization whenever possible, because it keeps the listing of scripts and programs shorter and easier to understand (at least for those with experience in \langname{R}). However, there is another very important reason: execution speed. The reason behind this is that \langname{R} is an interpreted language. In current versions of \langname{R} it is possible to byte-compile functions, but this is rarely used for scripts, and even byte-compiled loops are usually much slower to execute than vectorized functions.

However, there are cases were we need to repeatedly execute statements in a way that cannot be vectorized, or when we do not need to maximize execution speed. The \langname{R} language does have loop constructs, and we will describe them next.

\subsection{Iteration}
\index{for@\code{for}}\index{iteration!for loop}
We give the name \emph{iteration} to the process of repetitive execution of a program statement (simple or compound)---e.g.\ computed by iteration. We use the same word, iteration, also to name each one of these repetitions of the execution of a statement--e.g.\ the second iteration. 

The section of computer code being executed multiple times, conforms a loop (a closed path). Most loops contain a condition that determines when execution will continue outside the loop. The most frequently used type of loop is a \code{for} loop. These loops work in R on lists or vectors of values to act upon.

<<for-0>>=
b <- 0
for (a in 1:5) b <- b + a
b
b <- sum(1:5) # built-in function
b
@

Here the statement \code{b <- b + a} is executed five times, with variable \code{a} sequentially taking each of the values in \code{1:5}. Instead of a simple statement used here, also a compound statement could have been used for the body of the \code{for} loop.

Here are a few additional examples showing some of the properties of \code{for} loops and functions, combined with the use of a function.

<<for-3>>=
test.for <- function(x) {
  for (i in x) {print(i)}
}
test.for(numeric(0))
test.for(1:3)
test.for(NA)
test.for(c("A", "B"))
test.for(c("A", NA))
test.for(list("A", 1))
test.for(c("z", letters[1:4]))
@

In contrast to other languages, in \Rpgrm function arguments are not checked for `type' when the function is called. The only requirement is that the function code can handle the argument provided. In this example you can see that the same function works with numeric and character vectors, and with lists. We haven't seen lists before. As earlier discussed all elements in a vector should have the same type. This is not the case for lists. It is also interesting to note that a list or vector of length zero is a valid argument to \code{for()}, that triggers no error, but that as one would expect, causes the statements in the loop body to be skipped.

Some examples of use of \code{for} loops --- and of how to avoid their use.

<<for-1>>=
a <- c(1, 4, 3, 6, 8)
for(x in a) x*2 # result is lost
for(x in a) print(x*2) # print is needed!

b <- for(x in a) x*2 # does not work as expected, but triggers no error
b

for(x in a) b <- x*2 # a bit of a surprise, as b is not a vector!

b <- numeric()
for(i in seq(along.with = a)) {
  b[i] <- a[i]^2
  print(b)
}
b # is a vector!
# a bit faster if we first allocate a vector of the required length
b <- numeric(length(a))
for(i in seq(along.with = a)) {
  b[i] <- a[i]^2
  print(b)
}
b # is a vector!
# vectorization is simplest and fastest
b <- a^2
b
@

\code{seq(along.with = a)} builds a new numeric vector with a sequence of the same length as vector \code{a}, passed as argument to parameter \code{along.width}.

\begin{playground}\label{box:play:forloop}
Look at the results from the above examples, and try to understand where does the returned value come from in each case. In the code chunk above, \Rfunction{print()} is used within the \emph{loop} to make intermediate values visible. You can add additional \code{print()} statements to visualize other variables such as \code{i} or run parts of the code, such as \code{seq(along.with = a)}, by themselves.

In this case, the code examples are valid, but the same approach can be used for debugging syntactically correct code that does not return the expected results, either for every input value, or with a specific value as input.
\end{playground}

\begin{warningbox}
In the examples above we show the use of \code{seq()} passing a vector as argument to its parameter \code{along.with}. This approach is much better than using the not exactly equivalent call to \code{seq()} based on the length of the vector, or its short version using operator \code{:}.

<<>>=
a <- c(1, 4, 3, 6, 8)
# a <- numeric(0)

b <- numeric(length(a))
for(i in seq(along.with = a)) {
  b[i] <- a[i]^2
}
print(b)

c <- numeric(length(a))
for(i in 1:length(a)) {
  c[i] <- a[i]^2
}
print(c)
@

With \code{a} of length 1 or longer, the statements are equivalent, but when \code{a} has length zero the two statements are no longer equivalent. Run the statements above, after un-commenting the second definition of \code{a} and try to understand \emph{why} they behave as they do.

\textbf{Advanced note:} \langname{R} vectors are indexed starting with \code{1} while languages like \langname{C} and \langname{C++} use indexes starting from \code{0}. In addition, these languages, also differ from \langname{R} in how they handle vectors of length zero.

\end{warningbox}

We sometimes may not be able to use vectorization, or may be easiest to not use it. However, whenever working with large data sets, or many similar data sets, we will need to take performance into account. As vectorization usually also makes code simpler, it is good style to use it whenever possible.

<<for-2>>=
b <- numeric(length(a)-1)
for(i in seq(along.with = b)) {
  b[i] <- a[i+1] - a[i]
  print(b)
}
# although in this case there were alternatives, there
# are other cases when we need to use indexes explicitly
b <- a[2:length(a)] - a[1:length(a)-1]
b
# or even better
b <- diff(a)
b
@

\code{while} loops\index{iteration!while loops} are quite frequently also useful. Instead of a list or vector, they take a logical argument, which is usually an expression, but which can also be a variable. For example the previous calculation could be also done as follows.

<<while-1>>=
a <- c(1, 4, 3, 6, 8)
i <- 1
while (i < length(a)) {
  b[i] <- a[i]^2
  print(b)
  i <- i + 1
}
b
@

Here is another example. In this case we use the result of the previous iteration in the current one. In this example you can also see, that it is allowed to put more than one statement in a single line, in which case the statements should be separated by a semicolon (;).

<<while-2>>=
a <- 2
while (a < 50) {print(a); a <- a^2}
print(a)
@

\begin{playground}
Make sure that you understand why the final value of \code{a} is larger than 50.
\end{playground}

\begin{playground}
The statements above can be simplified to:
<<while-3>>=
a <- 2
while (a < 50) {print(a <- a^2)}
print(a)
@

Explain why this works, and how it relates to the support in \langname{R} of \emph{chained} assignments to several variables within a single statement like the one below.

<<while-4>>=
a <- b <- c <- 1:5
a
b
c
@
\end{playground}

\code{repeat}\index{iteration!repeat loops} is seldom used, but adds flexibility as \Rfunction{break()} can be located in the middle of the compound statement.

<<repeat-1>>=
a <- 2
repeat{
  print(a)
  a <- a^2
  if (a > 50) {print(a); break()}
}
# or more elegantly
a <- 2
repeat{
  print(a)
  if (a > 50) break()
  a <- a^2
}
@

\begin{playground}
Please, explain why the examples above return the values they do. Use the approach of adding \Rfunction{print()} statements, as described on page \pageref{box:play:forloop}.
\end{playground}

\subsection{Nesting of loops}\label{sec:nested:loops}
\index{iteration!nesting of loops}\index{nested iteration loops}

All the execution-flow control statements seen above can be nested. We will show an example with two \code{for} loops. We first need a matrix of data to work with:

<<nested-1>>=
A <- matrix(1:50, 10)
A
A <- matrix(1:50, 10, 5)
A
# argument names used for clarity
A <- matrix(1:50, nrow = 10)
A
A <- matrix(1:50, ncol = 5)
A
A <- matrix(1:50, nrow = 10, ncol = 5)
A
@

All the statements above are equivalent, but some are easier to read than others. We next show some alternative ways of coding nested loops.

<<nested-21>>=
row.sum <- numeric() # slower as size needs to be expanded
for (i in 1:nrow(A)) {
  row.sum[i] <- 0
  for (j in 1:ncol(A))
    row.sum[i] <- row.sum[i] + A[i, j]
}
print(row.sum)
@

<<nested-22>>=
row.sum <- numeric(nrow(A)) # faster
for (i in 1:nrow(A)) {
  row.sum[i] <- 0
  for (j in 1:ncol(A))
    row.sum[i] <- row.sum[i] + A[i, j]
}
print(row.sum)
@

Look at the output of these two examples to understand what is happening differently with \code{row.sum}.

The code above is very general, it will work with any size of two dimensional matrix, which is good programming practice. However, sometimes we need more specific calculations. \code{A[1, 2]} selects one cell in the matrix, the one on the first row of the second column. \code{A[1, ]} selects row one, and  \code{A[ , 2]} selects column two. In the example above the value of \code{i} changes for each iteration of the outer loop. The value of \code{j} changes for each iteration of the inner loop, and the inner loop is run in full for each iteration of the outer loop. The inner loop index \code{j} changes fastest.

\begin{playground}
1) modify the example above to add up only the first three columns of \code{A}, 2) modify the example above to add the last three columns of \code{A}.

Will the code you wrote continue working as expected if the number of rows in \code{A} changed? and what if the number of columns in \code{A} changed, and the required results still needed to be calculated for relative positions? What would happen if \code{A} had fewer than three columns? Try to think first what to expect based on the code you wrote. Then create matrices of different sizes and test your code. After that think how to improve the code, at least so that wrong results are not produced.
\end{playground}

Vectorization can be achieved in this case easily for the inner loop, as \langname{R} includes function \code{sum()} which returns the sum of a vector passed as its argument. Replacing the inner loop, which is the most frequently executed, by an efficient vectorized function can be expected to improve performance significantly. See section \ref{sec:performance:tuning} on page \pageref{sec:performance:tuning} for a brief description of tools for measuring performance and finding the bottlenecks that may be limiting it.

<<nested-3>>=
row.sum <- numeric(nrow(A)) # faster
for (i in 1:nrow(A)) {
  row.sum[i] <- sum(A[i, ])
}
print(row.sum)
@

\code{A[i, ]} selects row \code{i} and all columns. In \langname{R}, the row index always comes first, which is not the case in all programming languages.

Both explicit loops can be eliminated if we use an \emph{apply} function, such as \Rfunction{apply()}, \Rfunction{lapply()} and \Rfunction{sapply()}, in place of the outer \code{for} loop.\index{apply@\code{apply}}. See section \ref{sec:data:apply} on page \pageref{sec:data:apply} for details on the use of R's \emph{apply} functions.

<<nested-4>>=
row.sum <- apply(A, MARGIN = 1, sum) # MARGIN=1 inidcates rows
print(row.sum)
@

\begin{playground}
How would you change this last example, so that only the last three columns are added up? (Think about use of subscripts to select a part of the matrix.)
\end{playground}

There are many variants of \emph{apply} functions, both in base \langname{R} and exported by contributed packages. See section \ref{sec:data:apply} for details on the use of several of the later ones.

Calculating row sums is a frequent operation, so R has a built-in function for this. It is always worthwhile, when performance matters, to check if there is an existing function capable of doing the computations we need. In this case using \code{rowSums()} simplifies the code and optimizes performance.

<<nested-5>>=
rowSums(A)
@

\section{Object names as character strings}

In\index{object names}\index{object names!as character strings} all assignment examples before this section, we have given the object names to be assigned to, as part of expressions. Sometimes, in scripts or packages, we may want to provide the object name to be assigned to as a character string. This requires the use of function \Rfunction{assign()} instead of the operator \code{<-}. The statements bellow demonstrate this.

<<assignx-01>>=
assign("a", 9.99)
a
assign("b", a)
b
@

The two toy examples above do not demonstrate why one may want to use \code{assign()}. In scripts and package code there are a few typical cases where we may want to use character strings to store (future or existing) object names: 1) we may want to allow the user to provide names either interactively or as data as character objects, 2) in an iterative loop we may want to transverse a vector or list of object names, or 3) we may want to construct object names at runtime based on data or settings.

<<assignx-02>>=
for (i in 1:5) {
   assign(paste("zz_", i, sep = ""), i^2)
}
ls(pattern = "zz_*")
@

The complementary operation is to \emph{get} an object when we have available its name as a character string. We use function \Rfunction{get()}.

<<assignx-03>>=
a <- 555
get("a")
@

If we have available a character vector containing object names and we want to create a list containing these objects we can use function \Rfunction{mget()}. In the example below we use function \code{ls()} to obtain a character vector of object names matching a specific pattern.

<<assignx-04>>=
obj_names <- ls(pattern = "zz_*")
obj_lst <- mget(obj_names)
str(obj_lst)
@

\begin{playground}
Think of possible uses of functions \code{assign()}, \code{get()} and \code{mget()} in scripts you use or could use to analyze your own data (or from other sources). Write a script to implement this, and iteratively test and revise this script until the result produced by the script matches your expectations.
\end{playground}

\section{Packages}\label{sec:script:packages}
\index{packages!using}
In \langname{R} speak `library' is the location where `packages' are installed. Packages are sets of functions, and data, specific for some particular purpose, that can be loaded into an \langname{R} session to make them available so that they can be used in the same way as built-in \langname{R} functions and data. The function \code{library()} is used to load packages, already installed in the local \langname{R} library, into the current session, while the function \Rfunction{install.packages()} is used to install packages, either from a file, or directly from a repository in the internet into the library. When using RStudio it is easiest to use RStudio commands (which call \Rfunction{install.packages()} and \Rfunction{update.packages()}) to install and update packages.

<<packages-1>>=
library(graphics)
@

Currently there are many thousands of packages available. The most reliable source of packages is CRAN, as only packages that pass strict tests and are actively maintained are included. In some cases you may need or want to install less stable code, and this is also possible. With package \pkgname{devtools} it is even possible to install packages directly from Github, Bitbucket and a few other repositories. These later installations are always installations from source (see below).

\Rpgrm packages can be installed either from source, or from already built `binaries'. Installing from sources, depending on the package, may require quite a lot of additional software to be available. Under \pgrmname{MS-Windows}, very rarely the needed shell, commands and compilers are already available. Installing them is not too difficult (you will need \pgrmname{RTools}, and \pgrmname{\hologo{MiKTeX}}). However, for this reason it is the norm to install packages from binary \texttt{.zip} files under \pgrmname{MS-Windows}. Under Linux most tools will be available, or very easy to install, so it is usual to install packages from sources. For \pgrmname{OS X} (Apple Mac) the situation is somewhere in-between. If the tools are available, packages can be very easily installed from sources from within \RStudio. However, binaries are for most packages also readily available.

The development of packages is beyond the scope of the current book, and very well explained in the book \citetitle{Wickham2015} \autocite{Wickham2015}. However, it is still worthwhile mentioning a few things about the development of \Rpgrm packages. Using \RStudio it is relatively easy to develop your own packages. Packages can be of very different sizes. Packages use a relatively rigid structure of folders for storing the different types of files, and there is a built-in help system, that one needs to use, so that the package documentation gets linked to the R help system when the package is loaded. In addition to \langname{R} code, packages can call \langname{C}, \langname{C++}, \langname{FORTRAN}, \langname{Java}, etc. functions and routines, but some kind of `glue' is needed, as function call conventions and \emph{name mangling} depend on the programming language, and in many cases also on the compiler used. At least for \langname{C++}, the recently developed \pkgname{Rcpp} \langname{R} package makes the ``gluing'' extremely easy. See Chapter \ref{chap:R:performance} starting on page \pageref{chap:R:performance} for more information on performance-related and other limitations of \pgrmname{R} and how to solve possible bottlenecks.

One good way of learning how R works, is by experimenting with it, and whenever using a certain function looking at its help, to check what are all the available options. How much documentation is included with packages varies a lot, but many packages include comprehensive user guides or examples as \emph{vignettes} in addition to the help pages for individual functions or data sets.

