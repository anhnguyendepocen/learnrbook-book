% !Rnw root = appendix.main.Rnw

<<echo=FALSE, include=FALSE>>=
opts_chunk$set(opts_fig_wide)
opts_knit$set(concordance=TRUE)
opts_knit$set(unnamed.chunk.label = 'data-chunk')
@

\chapter{New grammars of Data}\label{chap:R:data}

\begin{VF}
Essentially everything in S[R], for instance, a call to a function, is an S[R] object. One viewpoint is that S[R] has self-knowledge. This self-awareness makes a lot of things possible in S[R] that are not in other languages.

\VA{Patrick J. Burns}{S Poetry}
\end{VF}

%\dictum[Patrick J. Burns (1998) S Poetry. \url{http://www.burns-stat.com/documents/books/s-poetry/}]{Essentially everything in S[R], for instance, a call to a function, is an S[R] object. One viewpoint is that S[R] has self-knowledge. This self-awareness makes a lot of things possible in S[R] that are not in other languages.}

<<echo=FALSE>>=
# set to TRUE to test non-executed code chunks and rendering of plots
eval_online_data <- FALSE
eval_yoctopuce <- FALSE
@

\section{Aims of this chapter}

Base \Rlang and the recommended packages (installed by default) include many functions for manipulating data. This is a complete set, that supports all the usually needed operations. These functions have stable and well described behaviour, so they should be preferred unless some of their limitations justify the use of alternatives defined in contributed packages. In the present chapter we aim at describing the new syntaxes introduced by the most popular of these extensions aiming at changing (usually improving one aspect at the expense of another) in various ways how we can manipulate data in \Rlang.

\section{Introduction}

By reading previous chapters, you have already become familiar with base \Rlang classes, methods, functions and operators for storing and manipulating data. Most of these had been originally designed to perform optimally on rather small data sets \autocite[see][]{Matloff2011}. The \Rlang implementation has been over the years improved significantly in performance and random-access memory in computers has become cheaper, making constraints imposed by the original design of \Rlang less limiting, but on the other hand, the size of data sets has also increased. Some contributed packages have aimed at improving performance by relying on different compromises between usability, speed and reliability than used for base \Rlang.

Package \pkgname{data.table} is the best example of an alternative implementation of data storage maximizing speed of processing for large data sets using a new semantics and requiring a new syntax. We could say that package \pkgname{data.table} is based on a ``grammar of data'' that is different to that in the \Rlang language. The compromise in this case has been the use of a less intuitive syntax, and by defaulting to call by reference of arguments instead of by copy, increasing the ``responsibility'' of the author of code defining new functions.

When a computation includes a chain of sequential operations, if using base \Rlang, we can either store at each step in the computation the returned value in a variable, or nest multiple function calls. The first approach is verbose, but allows readable scripts, specially if variable names are wisely chosen. The second approach becomes very difficult too read as soon as there is more than one nesting level. Attempts to find an alternative syntax have borrowed the concept of data \emph{pipes} from Unix shells \autocite{Kernigham1981}. Interestingly, that it has been possible to write packages that define the operators needed to ``add'' this new syntax to \Rlang is a testimony to its flexibility and extensibility. Two packages, \pkgname{magrittr} and \pkgname{wrapr}, define operators for pipe-based syntax.

A different aspect of the \Rlang syntax is extraction of members from lists and data frames by name. Base \Rlang provides two different operators for this, \code{\$} and \code{[]}, with different syntax. These two operators also differ in how \emph{incomplete names} are handled. Package \pkgname{tibble} alters this syntax for an alternative to base \Rlang's data frames. Once again, a new syntax allows new functionality at the expense of partial incompatibility with the base \Rlang syntax. Objects of class \code{"tb"} were also an attempt to improve performance compared to objects of class \code{"data.frame"}. \Rlang performance has improved in recent releases and currently even though performance is not the same, depending on the operations and data either \Rlang's data frames or tibbles perform better.

Base \Rlang function \Rfunction{subset()} has an unusual syntax, as it evaluates the expression passed as second argument within the data frame passed as its first argument (see \ref{sec:calc:df:with} on page \pageref{sec:calc:df:with}). This saves typing at the expense of increasing the risk of bugs as by reading the call to subset it is not obvious which names are resolved in the environment of the function and which ones within its first argument. In addition, changes elsewhere in a script can change how a call to subset is interpreted. In reality, subset is a wrapper function built on top of the extraction operator \code{[]}. It is a convenience function, mostly intended to be used at the console, rather than in scripts. To extract columns from a data frame is always best to use the \code{[[]]} operator with a character string as argument.

Package \pkgname{dplyr} provides convenience functions that work in a similar way as base \Rlang \code{subset()}. This package has suffered quite drastic changes during its development with respect of how to handle the dilemma caused by ``guessing'' of the environment where names should be looked up. There is no easy answer, a simplified syntax leads to ambiguity, and a fully specified syntax is verbose. Recent versions of the package introduced a terse syntax to achieve a concise way of specifying where to lookup for names. Apparently this syntax was found to be too obscure and a new change introduced. I guess the answer is as above, for code that needs to highly reliable and produce reproducible results we should at least for the time being use base \Rlang. For code that is to be used once, or for which reproducibility can depend on the use of a specific (old or soon to be old) version of \pkgname{dplyr} the conciseness of the new syntax will be an advantage.

In this chapter you will familiarise with the distinctive grammars of data as implemented in some of the packages that define alternative ways of manipulating data in \Rlang. As in previous chapters I will focus more on the available tools and how to use them than on their role in the analysis of data. The books \citebooktitle{Wickham2017} \autocite{Wickham2017} and \citebooktitle{Peng2016} \autocite{Peng2016} cover partly the same subjects from the perspective of data analysis.

\section{Packages used in this chapter}

<<eval=FALSE>>=
install.packages(learnrbook::pkgs_ch_data)
@

For executing the examples listed in this chapter you need first to load the following packages from the library:

<<message=FALSE>>=
library(learnrbook)
library(tibble)
library(magrittr)
library(wrapr)
library(stringr)
library(dplyr)
library(tidyr)
@

\section{Replacements for \texttt{data.frame}}

\subsection{\pkgname{data.table}}
The function call semantics of the \Rlang language is that arguments are passed to functions by copy. If the arguments are modified within the code of a function, these changes are local to the function. If implemented n√§ively this semantic would impose a huge toll on performance, however, \Rlang in most situations only makes a copy if and when the value changes. Consequently, for modern versions of \Rlang which are very good at avoiding unnecessary copying of objects, the normal \Rlang semantics has only a moderate negative impact on performance. However, this impact can be still a problem as modification is detected at the object level, and consequently \Rlang may make copies of for example even a huge data frame when only values in a single column or even just an attribute has changed.

Package \pkgname{data.table} passes arguments to functions by reference, avoiding making any copies, but any assignments within a function affect the variable passed as argument. This simplifies the needed tests and also by avoiding the need to make a copy of arguments to functions achieves the best possible performance. This is a specialized package but extremely useful when dealing with large data set. Writing user code, such as scripts, requires a good understanding of the pass-by-reference semantics. Package \pkgname{data.table} makes no attempt at backwards compatibility with base \Rlang \code{data.frame}.

\subsection{\pkgname{tibble}}\label{sec:data:tibble}

The authors of package \pkgname{tibble} describe their \Rclass{tbl} class as backwards compatible with \Rclass{data.frame} and make them a derived class. This backwards compatibility is only partial so in some situations they are not equivalent.

The class and methods that package \pkgname{tibble} defines lift some of the restrictions imposed be the design of base \Rlang data frames at the cost of creating some incompatibilities due to altered syntax for member extraction and by adding support for ``columns'' of class \Rclass{list} and removing support for columns of class \Rclass{matrix} (???). Handling of attributes is also differen, with no row names added by default. There are also differences in default behaviour of both constructors and methods. Although, objects of class \Rclass{tbl} can passed as arguments to most functions that expect data frames as input, not all of them are guaranteed to work correctly because of the change in syntax.

\begin{warningbox}
It is easy to write code that will work correctly both with data frames and tibbles. However, code that is syntactically correct according to the \Rlang language may fail if a tibble is used in place of a data frame.
\end{warningbox}

\begin{infobox}
In their first incarnation, the name for \Rclass{tibble} was \code{data\_frame} (with a dash instead of a dot). The old name is still recognized, but it is better to only use \Rfunction{tibble()} to avoid confusion. One should be aware that although the constructor \Rfunction{tibble()} and conversion function \Rfunction{as.tibble()}, as well as the test \Rfunction{is.tibble()} use the name \Rclass{tibble}, the class attribute is named \code{tbl}.

<<tibble-info-01>>=
my.tb <- tibble(numbers = 1:3)
is.tibble(my.tb)
class(my.tb)
@

Furthermore, by necessity, to support tibbles based on different underlying data sources a further derived class is needed. In our example, as our tibble has an underlying \code{data.frame} class, the most derived class of \code{my.tb} is \Rclass{tbl\_df}.
\end{infobox}

We start with the constructor and conversion methods. For this we will define our own diagnosis function.

<<tibble-01>>=
show_classes <- function(x) {
  cat(
    paste(paste(class(x)[1],
    "containing:"),
    paste(names(x),
          sapply(x, class), collapse = ", ", sep = ": "),
    sep = "\n")
    )
}
@

In the next two chunks we can see some of the differences. The \Rfunction{tibble()} constructor does not by default convert character data into factors, while the \Rfunction{data.frame()} constructor does.

<<tibble-02>>=
my.df <- data.frame(codes = c("A", "B", "C"), numbers = 1:3, integers = 1L:3L)
is.data.frame(my.df)
is.tibble(my.df)
show_classes(my.df)
@

Tibbles are data frames---or more formally class \Rclass{tibble} is derived from class \code{data.frame}. However, data frames are not tibbles.

<<tibble-03>>=
my.tb <- tibble(codes = c("A", "B", "C"), numbers = 1:3, integers = 1L:3L)
is.data.frame(my.tb)
is.tibble(my.tb)
show_classes(my.tb)
@

The \Rfunction{print()} method for tibbles, overrides the one defined for data frames.

<<tibble-04>>=
print(my.df)
print(my.tb)
@

\begin{playground}
An aesthetic difference is in how tibbles and data frames are printed when they have many rows. Construct a data frame and an equivalent tibble with at least 50 rows, and then test how the output looks when they are printed.
\end{playground}

Data frames can be converted into tibbles with \code{as.tibble()}.

<<tibble-05>>=
my_conv.tb <- as.tibble(my.df)
is.data.frame(my_conv.tb)
is.tibble(my_conv.tb)
show_classes(my_conv.tb)
@

<<tibble-06>>=
my_conv.df <- as.data.frame(my.tb)
is.data.frame(my_conv.df)
is.tibble(my_conv.df)
show_classes(my_conv.df)
@

\begin{playground}
Look carefully at the result of the conversions. Why do we now have a data frame with \code{A} as \code{character} and tibble with \code{A} as a \code{factor}?
\end{playground}

\begin{explainbox}
Not all conversion functions work consistently when converting from a derived class into its parent. The reason for this is disagreement between authors on what is the \emph{correct} behaviour based on logic and theory. You are not likely to be hit by this problem frequently, but it can be difficult to diagnose.

We have already seen that calling \Rfunction{as.data.frame()} on a tibble strips the derived class attributes, returning a data frame. We now look at the whole contents on the \code{"class"} attribute to better exemplify the problem. We also test the two objects for equality, in two different ways. Using the operator \code{==} tests for equivalent objects. Objects that contain the same data. Using \Rfunction{identical()} tests that objects are exactly the same, including attributes such as class.

<<tibble-box-01>>=
class(my.tb)
class(my_conv.df)
my.tb == my_conv.df
identical(my.tb, my_conv.df)
@

Now we derive from a tibble, and then attempt a conversion back into a tibble.

<<tibble-box-02>>=
my.xtb <- my.tb
class(my.xtb) <- c("xtb", class(my.xtb))
class(my.xtb)
my_conv_x.tb <- as_tibble(my.xtb)
class(my_conv_x.tb)
my.xtb == my_conv_x.tb
identical(my.xtb, my_conv_x.tb)
@

The two viewpoints on conversion functions are as follows. 1) The conversion function should return an object of its corresponding class, even if the argument is an object of a derived class, stripping the derived class. 2) If the object is of the class to be converted to, including objects of derived classes, then it should remain untouched. Base \Rlang follows, as far as I have been able to work out, approach 1). Packages in the \pkgname{tidyverse} follow approach 2). If in doubt about the behaviour of some function, then you need to do a test similar to the I have presented in the chunks in this box.
\end{explainbox}

There are additional important differences between the constructors \Rfunction{tibble()} and \Rfunction{data.frame()}. One of them is that in a call to \Rfunction{tibble()}, member variables (``columns'')  being defined can be used in the definition of subsequent member variables.

<<tibble-07>>=
tibble(a = 1:5, b = 5:1, c = a + b, d = letters[a + 1])
@

\begin{playground}
What is the behaviour if you replace \Rfunction{tibble()} by \Rfunction{data.frame()} in the statement above?
\end{playground}

While data frame columns can be factors, vectors or matrices (with the same number of rows as the data frame), columns of tibbles can be factors, vectors or lists (with the same number of members as rows the tibble has).

<<tibble-08>>=
tibble(a = 1:5, b = 5:1, c = list("a", 2, 3, 4, 5))
@

Which even allows a list of lists as a variable, or a list of vectors.

<<tibble-09>>=
tibble(a = 1:5, b = 5:1, c = list("a", 1:2, 0:3, letters[1:3], letters[3:1]))
@

\section{Data pipes}

The first obvious difference between scripts using some of the new grammars is the use of \emph{pipes}. Pipes have been at the core of shell scripting in \osname{Unix} since early stages of its design \cite{Kernigham1981}. Within an OS, pipes are chains of small programs that carry out a single well defined task (e.g.\ \code{ed}, \code{gsub}, \code{grep}, \code{more}, etc.). Data such as text is described as flowing from a source into a sink through a series of steps at which a specific transformation takes place. In \osname{Unix} sinks and sources are files, but files as an abstraction include all devices and connections for input or output, including physical ones as terminals and printers. The connection between steps in the pipe is usually implemented by means of temporary files.

<<pipes-x01,engine="bash",eval=FALSE>>=
stdin | grep("abc") | more
@

How can \emph{pipes} exist within a single \Rlang script? Within \Rlang data sources and sinks are \Rlang objects and instead of programs being chained into a pipe, functions are chained. The connection between functions is through temporary \Rlang objects stored in memory instead of through temporary OS files stored on disk. As an abstraction there is no difference.

What do pipes achieve in \Rlang scripts? They relieve the user from the responsibility of creating and deleting the temporary objects and of enforcing the sequential execution of the different steps. Once a bug-free script is developed, pipes by allowing more concise code, usually improve readability (for humans).

\subsection{\pkgname{magrittr}}

The operators needed to build pipes of \Rlang functions are implemented in package \pkgname{magrittr}. This implementation is used in the \pkgname{tidyverse} packages.
We start with a toy example first written using separate steps and normal \Rlang syntax

<<pipes-x02>>=
data.in <- 1:10
data.tmp <- sqrt(data.in)
data.out <- sum(data.tmp)
rm(data.tmp) # clean up!
@

next using nested function calls still using normal \Rlang syntax

<<pipes-x03>>=
data.out <- sum(sqrt(data.in))
@

written as a pipe using the chaining operator from package \pkgname{magrittr}.

<<pipes-x04>>=
data.in %>% sqrt() %>% sum() -> data.out
@

\begin{explainbox}
The \Roperator{\%>\%} from package \pkgname{magrittr} takes two operands. The value returned by the \emph{lhs} (left hand side) operand, which can be any \Rlang expression, is passed as first argument to the \emph{rhs} operand, which must be must be a function accepting at least one argument. Consequently, the function in the \emph{rhs} must have a suitable signature for the pipe to work and it is impossible to pass piped arguments by name or to any other parameter than the first one.

Some base \Rlang functions like \code{subset()} have a signature that is suitable for use in pipes, while using \code{assign()} in a pipe will in most cases require defining a wrapper function to change the order of the formal parameters.
\end{explainbox}

\subsection{\pkgname{wrapr}}

The \Roperator{\%.>\%} or ``dot-pipe'' operator from pakage \pkgname{wrapr} adds more ``sugar'' by allowing expressions both on rhs and lhs, and any position in the rhs for the piped value.

Rewritten using the dot-pipe operator the pipe in the previous chunk becomes

<<pipes-x05>>=
data.in %.>% sqrt(.) %.>% sum(.) -> data.out
@

This operator allows us to do things like, which \Roperator{\%>\%} does not allow.

<<pipes-x06>>=
data.in %.>% (2 + .^2) %.>% assign("data.out", .)
@

If needed or desired named arguments are supported.

<<pipes-x07>>=
data.in %.>% (2 + .^2) %.>% assign(value = ., x = "data.out")
@

\begin{warningbox}
\Rlang syntax for expressions is preserved, with the only caveat that because of the low precedence of the \Roperator{\%.>\%} operator we need to ``protect'' bare expressions containing other operators by enclosing them in parentheses.
\end{warningbox}

In the rest of the chapter we will exclusively use dot pipes in examples to ensure readability.

Although pipes are what make the scripts visually very different, from the point of view of data analysis what makes pipes most convenient to use are some of the new classes, functions and methods defined in package \pkgname{dplyr} and other \pkgname{tidyverse} packages.

\section{Reshaping with \pkgname{tidyr}}

Data stored in table-like formats can be arranged in different ways. In base \Rlang most model fitting functions and the \Rfunction{plot()} using (model) formulas and accepting data frames, expect data to be arranged in ``long form'' so that each row in a data frame corresponds to a single observation (or measurement) event on a subject. Each column corresponds to a different measured feature, time of measurement or a factor describing a classification of subjects according to treatments or features of the experimental design (e.g.\ blocks). Covariates measured on the same subject at an earlier point in time may be also stored in a column. Data arranged in long form has been nicknamed as ``tidy'' and this is reflected in the name given to the \pkgname{tidyverse} suite of packages. Data in which columns correspond to measurement events is described as being in a ``wide form''.

Although long-form data is and has been the most commonly used arrangement of data in \Rlang, not always manipulation of such data has been possible with concise \Rlang statements. The packages in the \pkgname{tidyverse} provide convenience functions to simplify coding of data manipulation, which in some cases have in addition improved performance compared to base \Rlang---i.e.\ it is possible to code the same operations using only base \Rlang, but may require more and longer statements.

Real-world data is frequently stored in wide format or even ad-hoc formats, so frequently the first task in data analysis is to reshape the data. Package \pkgname{tidyr} provides functions for ``reshaping'' data (replacing the older packages \pkgname{reshape} and \pkgname{reshape2}) from wide- to long form and \emph{vice versa}).

%% replace iris with an example that is really ``wide''
Some operations on \Rlang \code{data.frame} objects with \pkgname{tidyverse} packages will return \code{data.frame} objects and others tibbles---i.e.\ \code{tb} objects. Consequently it is safer to convert into tibbles the objects we will work with.

<<tidy-tibble-00>>=
iris.tb <- as_tibble(iris)
@

Function \Rfunction{gather()} converts data from wide form into long form (or ''tidy''). We use as an example the \Rdata{iris.tb} data set included in base \Rlang. We use \code{gather} to obtain a long-form tibble. By comparing \code{iris.tb} with \code{long\_iris.tb} we can appreciate how \Rfunction{gather()} reshaped its input.

<<tidy-tibble-01>>=
head(iris.tb, 2)
iris.tb %.>%
  gather(., key = part, value = dimension, -Species) -> long_iris.tb
head(long_iris.tb, 2)
@

In this statement we can see the convenience of dispensing with quotation marks for the new (\code{part} and \code{dimension} and existing \code{Species} column names.

\begin{warningbox}
However, altering the normal interpretation of the name passed as argument to \code{key} and \code{value} prevents these arguments to be recognised as the name of a variable. We need to use a new operator \code{!!} to restore the normal \Rlang behaviour.

<<tidy-tibble-01a>>=
part <- "not part"
long_iris.tb_2 <- gather(iris.tb, key = !!part, value = dimension, -Species)
head(long_iris.tb_2)
@

This syntax has been recently subject to debate and lead to John Mount developing package \pkgname{seplyr} which provides wrappers on functions and methods from \pkgname{dplyr} that respect standard evaluation. At the time of writing \pkgname{seplyr} could considered as experimental.
\end{warningbox}

\begin{playground}
To better understand why I added \code{-Species} as an argument, edit the code removing it, and execute the statement to see how the returned tibble is different.
\end{playground}

For the reverse operation, converting from long form to wide form we use \Rfunction{spread()}.

<<tidy-tibble-01b, eval=FALSE>>=
spread(long_iris.tb, key = c(!!part, Species), value = dimension) # does not work!!
@

\section{Data manipulation with \pkgname{dplyr}}

\begin{warningbox}
The first advantage a user of the \pkgname{dplyr} functions and methods sees is the completeness of the set of operations supported and the symmetry and consistency among the different functions. A second advantage is that almost all the functions are defined not only for objects of class \Rclass{tibble}, but also for objects of class \code{data.table} and for SQL databases, with consistent syntax (See packages \pkgname{dtplyr} and \pkgname{dbplyr}). A further variant exists in package \pkgname{seplyr}, supporting a different syntax stemming from the use ``standard evaluation'' (SE) instead of non-standard evaluation (NSE). A downside of \pkgname{dplyr} and much of the \pkgname{tidyverse} is that the syntax is not yet stable, and additionally, some function and method names either override those in base \Rlang or clash with names used in other packages. \Rlang itself is much more stable and expected to remain forward and backward compatible for a long time. For code intended to remain in use for years, the fewer packages it depends on, the less maintenance it will need. When using the \pkgname{tidyverse} we need to be prepared to revise our own dependent code after any major revision to any of the packages used.
\end{warningbox}

\subsection{Row-wise manipulations}

Assuming that the data is stored in long form, row-wise operations consist in operations combining values from the same observation event and unit---i.e.\ calculations within a single row of a data frame or tibble. Using functions \Rfunction{mutate()} and \Rfunction{transmute()} we can obtain derived quantities by combining different variables, or variables and constants, or applying a mathematical transformation. We add new variables (columns) retaining existing ones using \Rfunction{mutate()} or we assemble a new tibble containing only the columns we explicitly specify using \Rfunction{transmute()}. Differently to usual \Rlang syntax, we can use values calculated in previous arguments in later ones.

Continuing with the example from the previous section, we most likely would like to split the values in variable \code{part} into \code{plant\_part} and \code{part\_dim}. We use \code{mutate()} from \pkgname{dplyr} and \Rfunction{str\_extract()} from \pkgname{stringr}. We use regular expressions as arguments passed to \code{pattern}.  We do not show it here, but \Rfunction{mutate()} can be used with variables of any \code{mode}, and calculations can involve values from several columns. It is even possible to operate on values applying a lag or in other words using rows displaced relative to the current one. As shown in the example in section \ref{sec:dataex:birch} on page \pageref{sec:dataex:birch}, within a single call to \Rfunction{mutate()} values calculated first can be used in the calculations for later variables.

<<tidy-tibble-02>>=
long_iris.tb %.>%
  mutate(.,
         plant_part = str_extract(part, "^[:alpha:]*"),
         part_dim = str_extract(part, "[:alpha:]*$")) -> long_iris.tb
summary(long_iris.tb)
@

In the next few chunks we print the returned values rather than saving then in variables. In most cases in practice one will combine these function into a ``pipe'' using operator \Roperator{\%.>\%} (see section \ref{sec:data:pipes} on page \pageref{sec:data:pipes}, and for more realistic examples, section \ref{sec:dataex} starting on page \pageref{sec:dataex}).

Function \Rfunction{arrange()} is used for sorting the rows---makes sorting a data frame simpler than by using \Rfunction{sort()} and \Rfunction{order()}. At a cost as these two base \Rlang methods are more versatile than \Rfunction{arrange()}.

<<tidy-tibble-03>>=
arrange(long_iris.tb, Species, plant_part, part_dim)
@

Function \Rfunction{filter()} can be used to extract a subset of rows---similar to \Rfunction{subset()} but with a syntax consistent with that of other functions in the \pkgname{tidyverse}.

<<tidy-tibble-04>>=
filter(long_iris.tb, plant_part == "Petal")
@

Function \Rfunction{slice()} can be used to extract a subset of rows based on their positions---would be done with positional (numeric) indexes with \code{[ , ]} in base \Rlang passing them to the first argument.

<<tidy-tibble-05>>=
slice(long_iris.tb, 1:5)
@

Function \Rfunction{select()} can be used to extract a subset of columns--would be done with positional (numeric) indexes with \code{[ , ]} in base \Rlang passing them to the second argument, as numeric indexes or column names as a character vector. Negative indexes in base \Rlang can only be numeric, while \Rfunction{select()} accepts bare column names prepended with a minus for exclussion.

<<tidy-tibble-06>>=
select(long_iris.tb, -part)
@

In addition \Rfunction{select()} as other functions in \pkgname{dplyr} accept ``selectors'' returned by functions \Rfunction{starts\_with()}, \Rfunction{ends\_with()}, \Rfunction{contains()}, and \Rfunction{matches()} to extract or retain columns. For this example we use \Rlang \code{iris.tb} instead of our \code{long\_iris.tb}.

<<tidy-tibble-06a>>=
select(iris.tb, -starts_with("Sepal"))
@

<<tidy-tibble-06b>>=
select(iris.tb, Species, matches("pal"))
@

Function \Rfunction{rename()} can be used to rename columns---while base \Rlang requires the use of both \Rfunction{names()} and \Rfunction{names<-()} and \emph{ad hoc} code to match the new and old names.

<<tidy-tibble-07>>=
rename(long_iris.tb, dim = dimension)
@

\subsection{Group-wise manipulations}

Another important operation is to summarize quantities by group of rows. Contrary to base \Rlang, the grammar of data manipulation, splits this operation in two: the setting of the grouping, and the calculation of summaries. This simplifies the code, making it more easily understandable when using pipes compared to the approach of base \Rlang \Rfunction{aggregate()}, and it also makes it easier to summarize several columns in a single operation.

\begin{warningbox}
It is important to be aware that grouping is persistent, and may affect also other operations on the same data frame or tibble if it is saved or piped and reused. Grouping is invisible to users except for its side-effects and because of this can lead erroneous and surprising results from calculations. Do not save grouped tibbles or data frames, always make sure that inputs and outputs, at the head and tail of a pipe are not grouped, using \Rfunction{ungroup()} when needed.
\end{warningbox}

The first step is to use \Rfunction{group\_by()} to ``tag'' a tibble with the grouping. We create a \emph{tibble} and then convert it into a \emph{grouped tibble}. Once we have a grouped tibble, function \Rfunction{summarise()} will recognize the grouping and use it when the summary values are calculated.

<<tibble-grouped-01>>=
tibble(numbers = 1:9, letters = rep(letters[1:3], 3)) %.>%
  group_by(., letters) %.>%
  summarise(.,
            mean_numbers = mean(numbers),
            median_numbers = median(numbers),
            n = n())
@

\begin{warningbox}
\textbf{How is grouping implemented for data frames and tibbles?} In our case as our tibble belongs to class \code{tibble\_df}, grouping adds \code{grouped\_df} as the most derived class. It also adds several attributes with the grouping information in a format suitable for fast selection of group members. To demonstrate this, we need to make an exception to our recomendation above and save a grouped tibble to a variable.

<<tibble-grouped-box-01>>=
my.tb <- tibble(numbers = 1:9, letters = rep(letters[1:3], 3))
is.grouped_df(my.tb)
class(my.tb)
names(attributes(my.tb))
@

<<tibble-grouped-box-02>>=
my_gr.tb <- group_by(.data = my.tb, letters)
is.grouped_df(my_gr.tb)
class(my_gr.tb)
names(attributes(my_gr.tb))
@

<<tibble-grouped-box-03>>=
my_ugr.tb <- ungroup(my_gr.tb)
class(my_ugr.tb)
names(attributes(my_ugr.tb))
@

<<tibble-grouped-box-04>>=
all(my.tb == my_gr.tb)
all(my.tb == my_ugr.tb)
identical(my.tb, my_gr.tb)
identical(my.tb, my_ugr.tb)
@

The tests above show that members are in all cases the same as operator \Roperator{==} tests for equality at each position, while attributes, including \code{class} differ between normal tibbles and grouped ones and so not \emph{identical} objects.

If we replace \code{tibble} by \code{data.frame} in the first statement, and rerun the chunk we result of the last statement in the chunk in \code{FALSE} instead of \code{TRUE}. At the time of writing starting with a \code{data.frame} object, applying grouping with \Rfunction{group\_by()} followed by ungrouping with \Rfunction{ungroup()} has the side effect of converting the data frame into a tibble. This is something to be very much aware of, as there are differences in how the extraction operator \Roperator{[ , ]} behaves in the two cases. The safe way to write \pkgname{tidyverse} code is to always use tibbles instead of data frames.

Use function \Rfunction{attributes()} to compare the attributes of  \code{my.tb} and \code{my\_gr.tb}.
\end{warningbox}

\subsection{Joins}

Joins allow us to combine two data sources which share some variables. Variables in common are used to match the corresponding rows before ``joining'' variables (i.e.\ columns) from both sources together. There are several \emph{join} functions in \pkgname{dplyr}. They differ mainly in how they handle rows that do not have a match between data sources.

We create here some artificial data to demonstrate the use of these functions. We will create two small tibbles, with one column in common and one mismatched row in each.

<<joins-00>>=
first.tb <- tibble(idx = c(1:4, 5), values1 = "a")
second.tb <- tibble(idx = c(1:4, 6), values2 = "b")
@

Bellow we apply the \emph{mutating join} functions exported by \pkgname{dplyr}: \Rfunction{full\_join()}, \Rfunction{left\_join()}, \Rfunction{right\_join()} and \Rfunction{inner\_join()}. These functions always retain all columns, and in case of multiple matches keep a row for each matching combination of rows. We repeat each example with the arguments passed to \code{x} and \code{y} swapped to more clearly show their different behaviour.

A full join retains all unmatched rows filling missing values with \code{NA}. By default the match is done on columns with the same name in \code{x} and \code{y}, but this can be changed by passing an argument to parameter \code{by}. Using \code{by} one can base the match on columns that have different names in \code{x} and \code{y}, or prevent matching of columns with the same name in \code{x} and \code{y} (example at end of the section).

<<joins-01>>=
full_join(x = first.tb, y = second.tb)
@

<<joins-01a>>=
full_join(x = second.tb, y = first.tb)
@

Left and right joins retain rows not matched from only one of the two data sources, \code{x} and \code{y}, respectively.

<<joins-02>>=
left_join(x = first.tb, y = second.tb)
@

<<joins-02a>>=
left_join(x = second.tb, y = first.tb)
@

<<joins-03>>=
right_join(x = first.tb, y = second.tb)
@

<<joins-03a>>=
right_join(x = second.tb, y = first.tb)
@

An inner join discards all rows in \code{x} that do not have a matching row in \code{y} and vice versa.

<<joins-04>>=
inner_join(x = first.tb, y = second.tb)
@

<<joins-04a>>=
inner_join(x = second.tb, y = first.tb)
@

Next we apply the \emph{filtering join} functions exported by \pkgname{dplyr}: \Rfunction{semi\_join()} and \Rfunction{anti\_join()}. These functions only return a tibble always containing only the columns from \code{x}, but with retaining rows based on their match to rows in \code{y}.

A semi join retains rows from \code{x} that have a match in \code{y}.

<<joins-05>>=
semi_join(x = first.tb, y = second.tb)
@

<<joins-05a>>=
semi_join(x = second.tb, y = first.tb)
@

A anti join retains rows from \code{x} that do not have a match in \code{y}.

<<joins-06>>=
anti_join(x = first.tb, y = second.tb)
@

<<joins-06a>>=
anti_join(x = second.tb, y = first.tb)
@

We here rename column \code{idx} in \code{first.tb} to demonstrate the use of \code{by}.

<<joins-01b>>=
first2.tb <- rename(first.tb, idx2 = idx)
full_join(x = first2.tb, y = second.tb, by = c("idx2" = "idx"))
@

<<eco=FALSE>>=
try(detach(package:lubridate))
try(detach(package:tidyr))
try(detach(package:dplyr))
try(detach(package:stringr))
try(detach(package:wrapr))
try(detach(package:magrittr))
try(detach(package:tibble))
try(detach(package:learnrbook))
@

<<eval=eval_diag, include=eval_diag, echo=eval_diag, cache=FALSE>>=
knitter_diag()
R_diag()
other_diag()
@
