% !Rnw root = appendix.main.Rnw
<<echo=FALSE, include=FALSE>>=
opts_chunk$set(opts_fig_wide)
opts_knit$set(concordance=TRUE)
opts_knit$set(unnamed.chunk.label = 'functions-chunk')
@

\chapter{The R language: adding ``words''}\label{chap:R:functions}

\begin{VF}
Computer Science is a science of abstraction---creating the right model for a problem and devising the appropriate mechanizable techniques to solve it.

\VA{Alfred V. Aho and Jeffrey D. Ullman}{Foundations of Computer Science}
\end{VF}

%\dictum[Alfred V. Aho, Jeffrey D. Ullman, \emph{Foundations of Computer Science}, Computer Science Press, 1992]{Computer Science is a science of abstraction---creating the right model for a problem and devising the appropriate mechanizable techniques to solve it.}\vskip2ex

\section{Aims of this chapter}

In earlier chapters we have only used base \Rlang features. In this chapter you will learn how to expand the range of features available. In the first part of the chapter I will focus on using existing packages to expand the functionality of \Rlang. In the second part you will learn how to define new functions and classes by yourself. We will not consider the important, but more advanced question of packaging functions and classes into new packages.

\section{Packages}\label{sec:script:packages}

\subsection{Download, installation and used}

\index{packages!using}
In \langname{R} speak `library' is the location where `packages' are installed. Packages are sets of functions, and data, specific for some particular purpose, that can be loaded into an \langname{R} session to make them available so that they can be used in the same way as built-in \langname{R} functions and data. The function \code{library()} is used to load packages, already installed in the local \langname{R} library, into the current session, while the function \Rfunction{install.packages()} is used to install packages, either from a file, or directly from a repository in the internet into the library. When using RStudio it is easiest to use RStudio commands (which call \Rfunction{install.packages()} and \Rfunction{update.packages()}) to install and update packages.

<<packages-1>>=
library(graphics)
@

Currently there are many thousands of packages available. The most reliable source of packages is CRAN, as only packages that pass strict tests and are actively maintained are included. In some cases you may need or want to install less stable code, and this is also possible. With package \pkgname{devtools} it is even possible to install packages directly from Github, Bitbucket and a few other repositories. These later installations are always installations from source (see below).

\Rpgrm packages can be installed either from source, or from already built `binaries'. Installing from sources, depending on the package, may require quite a lot of additional software to be available. Under \pgrmname{MS-Windows}, very rarely the needed shell, commands and compilers are already available. Installing them is not too difficult (you will need \pgrmname{RTools}, and \pgrmname{\hologo{MiKTeX}}). However, for this reason it is the norm to install packages from binary \texttt{.zip} files under \pgrmname{MS-Windows}. Under Linux most tools will be available, or very easy to install, so it is usual to install packages from sources. For \pgrmname{OS X} (Apple Mac) the situation is somewhere in-between. If the tools are available, packages can be very easily installed from sources from within \RStudio. However, binaries are for most packages also readily available.

The development of packages is beyond the scope of the current book, and very well explained in the book \citetitle{Wickham2015} \autocite{Wickham2015}. However, it is still worthwhile mentioning a few things about the development of \Rpgrm packages. Using \RStudio it is relatively easy to develop your own packages. Packages can be of very different sizes. Packages use a relatively rigid structure of folders for storing the different types of files, and there is a built-in help system, that one needs to use, so that the package documentation gets linked to the R help system when the package is loaded. In addition to \langname{R} code, packages can call \langname{C}, \langname{C++}, \langname{FORTRAN}, \langname{Java}, etc. functions and routines, but some kind of `glue' is needed, as function call conventions and \emph{name mangling} depend on the programming language, and in many cases also on the compiler used. At least for \langname{C++}, the recently developed \pkgname{Rcpp} \langname{R} package makes the ``gluing'' extremely easy. See Chapter \ref{chap:R:performance} starting on page \pageref{chap:R:performance} for more information on performance-related and other limitations of \pgrmname{R} and how to solve possible bottlenecks.

One good way of learning how R works, is by experimenting with it, and whenever using a certain function looking at its help, to check what are all the available options. How much documentation is included with packages varies a lot, but many packages include comprehensive user guides or examples as \emph{vignettes} in addition to the help pages for individual functions or data sets. It is not unusual to decide which package to use from a set of alternatives based on the available documentation. In the case of some packages adding many new capabilities, packages may be documented in depth in a whole book. Well known examples are \citetitle{Pinheiro2000} \autocite{Pinheiro2000}, \citetitle{Sarkar2008} \autocite{Sarkar2008} and \citetitle{Wickham2016} \autocite{Wickham2016}.

\begin{warningbox}
\textbf{Naming conflicts} When two objects with the same name are present in the search path used by R to match names to stored objects, conflicts can occur. Not all names belong to the same namespace, and consequently, in many situations different object with identical names can coexist in the R environment. It is important that you realize than in such cases all these objects remain within reach of our code, but that the one nearest to the top of the search path will returned when a ``plain'' name is used. The name of the namespace can be prepended to that of the object separated by double colons (\code{::}). In recent versions of R, every package is required to use a namespace to isolate the names used, and even names used in base R are in their own name space. This greatly facilitates the resolution of naming conflicts.
    
<<namespaces-00>>=
mean(1:5)
base::mean(1:5)
@

If no packages are loaded or if the loaded packages and user code do not reuse the name ``mean'', the two statements above are identical. If \code{mean} is redefined in user code, or exported by a package that has been loaded, the first statement will refer to the redefinition, while the second statement will continue to refer to the definition in base R.

When using packages naming conflicts can rather easily occur among packages. On the other hand very few packages use names for objects, classes or functions that are already in use in base R, and when they do, these are sometimes backwards compatible with the objects they hide. In general it is bad practice to redefine names from base R as those names are part the language, and a change in the behaviour of the R language is unexpected by users. In addition, such redefinitions can make valid R language scripts invalid, or result in the return wrong results. In many other computer programming languages, such reuse of names is disallowed and enforced: such a program is illegal and impossible to execute. R is more permissive, and this is sometimes useful, but only in exceptional cases such reuse of names can be considered as being within ``good coding practice''.

In production code, and specially when writing packages, one should use the namespace plus name notation for any names not defined within the package itself, to ensure that the package can reliable work independently of the names used in user code and any other packages concurrently loaded. In many cases, using the double colon notation makes the code of a script easier to read, although at the cost of a loss of conciseness.
\end{warningbox}

\subsection{Finding suitable packages}

There being so many different contributed R packages, can make it difficult to find a suitable package for a task at hand. It is good to first check if the necessary capability is already built within base R. Base R plus the recommended packages (installed when R is installed) cover a lot of ground. To analyse data using almost any of the more common statistical methods does not require the use of special packages. Sometimes, contributed packages duplicate and or extend the functionality in base R with advantage. When one considers the use of novel or specialized types of data analysis, the use of contributed packages can be unavoidable. Even in such cases, it is not unusual to have alternatives to chose from within the available contributed packages.


\section{Functions}\label{sec:script:functions}
\index{functions!defining new}

When writing scripts, or any program, one should avoid repeating blocks of code (groups of statements). The reasons for this are: 1) if the code needs to be changed---e.g.\ to fix a bug or error---, you have to make changes in more than one place in the file, or in more than one file. Sooner or later, some copies will remain unchanged by mistake. This leads to inconsistencies and hard to track bugs; 2) it makes the script file longer, and this makes debugging, commenting, etc. more tedious, and error prone; 3) abstraction and division of a problem into smaller chunks, helps with keeping the code understandable to humans.

How do we avoid repeating bits of code? We write a function containing the statements that we would need to repeat, and then \emph{call} (``use'') the function in their place.

Functions are defined by means of \Rfunction{function()}, and saved like any other object in \Rpgrm by assignment to a variable. In the example below \code{x} and \code{y} are both formal parameters, or names used within the function for objects that will be supplied as ``arguments'' when the function is called. One can think of parameter names as place-holders.

<<fun-00>>=
my.prod <- function(x, y){x * y}
my.prod(4, 3)
@

First\index{functions:arguments} some basic knowledge. In R, arguments are passed by copy. This is something very important to remember. Whatever you do within a function to modify an argument, its value outside the function will remain (almost) always unchanged.

<<fun-01>>=
my.change <- function(x){x <- NA}
a <- 1
my.change(a)
a
@

Any result that needs to be made available outside the function must be returned by the function. If the function \Rfunction{return()} is not explicitly used, the value returned by the last statement \emph{executed} within the body of the function will be returned.

\label{chunck:print:funs}
<<fun-02>>=
print.x.1 <- function(x){print(x)}
print.x.1("test")
print.x.2 <- function(x){print(x); return(x)}
print.x.2("test")
print.x.3 <- function(x){return(x); print(x)}
print.x.3("test")
print.x.4 <- function(x){return(); print(x)}
print.x.4("test")
print.x.5 <- function(x){x}
print.x.4("test")
@

Now we will define a useful function: a function for calculating the standard error of the mean from a numeric vector.

<<fun-1NN>>=
SEM <- function(x){sqrt(var(x) / length(x))}
a <- c(1, 2, 3, -5)
a.na <- c(a, NA)
SEM(x = a)
SEM(a)
SEM(a.na)
@

For example in \code{SEM(a)} we are calling function \Rfunction{SEM()} with \code{a} as argument.

The function we defined above may sometimes give a wrong answer because NAs will be counted by \code{length()}, so we need to remove NAs before calling \code{length()}.

<<fun-1-safe>>=
simple_SEM <- function(x) {
 sqrt(var(x, na.rm=TRUE)/length(na.omit(x)))
}
a <- c(1, 2, 3, -5)
a.na <- c(a, NA)
simple_SEM(x=a)
simple_SEM(a)
simple_SEM(a.na)
@

R does not have a function for standard error, so the function above would be generally useful. If we would like to make this function both safe, and consistent with other R functions, one could define it as follows, allowing the user to provide a second argument which is passed as an argument to \Rfunction{var()}:

<<fun-2>>=
SEM <- function(x, na.rm = FALSE){
  sqrt(var(x, na.rm = na.rm) / length(na.omit(x)))
}
SEM(a)
SEM(a.na)
SEM(a.na, TRUE)
SEM(x = a.na, na.rm = TRUE)
SEM(TRUE, a.na)
SEM(na.rm = TRUE, x = a.na)
@

In this example you can see that functions can have more than one parameter, and that parameters can have default values to be used if no argument is supplied. In addition if the name of the parameter is indicated, then arguments can be supplied in any order, but if parameter names are not supplied, then arguments are assigned to parameters based on their position. Once one parameter name is given, all later arguments need also to be explicitly matched to parameters. Obviously if given by position, then arguments should be supplied explicitly for all parameters at `intermediate' positions.

%We can assign to a variable defined `outside' a function with operator \code{<<-} but the usual recommendation is to avoid its use. This type of effects of calling a function are frequently called `side-effects'.

\begin{playground}
Test the behaviour of functions \code{print.x.1()} and \code{print.x.5()}, as defined on page \pageref{chunck:print:funs}, at the command prompt, and in a script, by writing a script.
The behaviour of one of these functions will be different when the script is source than at the command prompt. Explain why.
\end{playground}

\begin{playground}
Define your own function to calculate the mean in a similar way as \Rfunction{SEM()} was defined above. Hint: function \Rfunction{sum()} could be of help.
\end{playground}

\begin{playground}
Create some additional vectors containing \code{NA}s or not. Use them to test functions \Rfunction{simple\_SEM()} and \Rfunction{SEM()} defined above, and then explain why \code{SEM()} returns always the correct value, even though ``\code{na.omit(x)}'' is non-conditionally (always) applied to \code{x} before calculating its length.
\end{playground}

\begin{explainbox}
\Rpgrm handles evaluation of function arguments differently to many other computer languages. Not only arguments are passed by value, but in addition they are evaluated only at the time of first use in the function body code. This is called \emph{lazy evaluation} and before evaluation arguments remain as \emph{promises}. In many cases this is advantageous by improving computation efficiency. However, if the value of the variable used as argument or in an expression used as argument changes, the value of the variable at the time of evaluation will be used. This is rarely a problem, but being aware of this behaviour is helpful specially when programmatically defining functions. Very rarely, an argument will not the evaluated when it should (e.g.\ because of bugs in packages, or use of ``trickery''). Earlier evaluation can be forced at any time with function \code{force()}.
\end{explainbox}

\section{Objects, classes and methods}\label{sec:script:objects:classes:methods}

An\index{objects}\index{classes}\index{methods} in-depth discussion of object oriented programming in \langname{R} is outside the scope of this book. Several books describe in detail the different class systems available and how to take best advantage of them when developing packages extending R. For the non-programmer user, a basic understanding can be useful, even if he or she do not intend to create new classes. This basic knowledge is what we intend to convey in this section. For an in-depth treatment of the subject please consult the recently published book \citetitle{Wickham2014} \autocite{Wickham2014}.

We start with a quotation form \citetitle{Burns1998} \autocite[][, page 13]{Burns1998}.
\begin{quotation}
The idea of object-oriented programming is simple, but carries a lot of weight.
Here's the whole thing: if you told a group of people ``dress for work'', then
you would expect each to put on clothes appropriate for that individual's job.
Likewise it is possible for S[R] objects to get dressed appropriately depending on
what class of object they are.
\end{quotation}

\langname{R} supports the use of the object oriented programming paradigm, but as a system that has evolved over the years, currently \langname{R} includes different approaches. The still most popular approach is called S3, and a more recent and powerful approach, with slower performance, is called S4. The general idea is that a generic name like ``plot'' can be used as a generic name, and that which specific version of \Rfunction{plot()} is called depends on the arguments of the call. Using computing terms we could say that the generic version of \Rfunction{plot()} dispatches the original call to different specific versions of \Rfunction{plot()} based on the class of the arguments passed. S3 generic functions dispatch, by default, based only on the argument passed to a single parameter, the first one. S4 generic functions can dispatch the call based on the arguments passed to more than one parameter and the structure of the objects of a given class is known to the interpreter. In S3 functions the specializations of a generic are recognized/identified only by their name. And the class of an object by a character string stored as an attribute to the object.

The most basic approach is to create a new class, pre-pending its name to the existing class attribute of an object. This would normally take place within a constructor.

<<explain-object-classes-01>>=
a <- 123
class(a)
class(a) <- c("myclass", class(a))
class(a)
@

Now we create a print method specific to \code{"myclass"} objects.
<<explain-object-classes-02>>=
print.myclass <- function(x) {
    sprintf("[myclass] %.g4", x)
}
@

Once a specialized method exists for a class, it will be used for objects of this class.

<<explain-object-classes-03>>=
print(a)
print(as.numeric(a))
@

The S3 class system is ``lightweight'' in that it adds very little additional computation load, but it is rather fragile in that most of the responsibility about consistency and correctness of the design---e.g.\ not messing up dispatch by redefining functions or loading a package exporting functions with the same name, etc.-- is not checked by the R interpreter.

Defining a new S3 generic is also quite simple. A generic method and a default method need to be created.

<<explain-object-classes-04>>=
my_print <- function (x, ...) {
   UseMethod("my_print", x)
 }

my_print.default <- function(x, ...) {
   print(class(x))
   print(x, ...)
}
@

<<explain-object-classes-05>>=
my_print(123)
my_print("abc")
@

Up to now, \Rfunction{my\_print()}, has no specialization. We now write one for data frames.

<<explain-object-classes-06>>=
my_print.data.frame <- function(x, rows = 1:5, ...) {
   print(x[rows, ], ...)
   invisible(x)
}
@

We add the second statement so that the function returns invisibly the whole data frame, rather than the lines printed. We now do a quick test of the function.

<<explain-object-classes-07>>=
my_print(cars)
my_print(cars, 8:10)
my_print(cars, TRUE)
b <- my_print(cars)
b
@

\begin{playground}
1) What would be the most concise way of defining a \code{my\_print()} specialization for \code{matrix}? Write one, and test it.
2) How would you modify the code of your \code{my\_print.matrix()} so that also columns to print can be selected?
\end{playground}

<<eval=eval_diag, include=eval_diag, echo=eval_diag, cache=FALSE>>=
knitter_diag()
R_diag()
other_diag()
@
