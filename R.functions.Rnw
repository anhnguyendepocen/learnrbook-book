% !Rnw root = appendix.main.Rnw

<<echo=FALSE, include=FALSE>>=
opts_chunk$set(opts_fig_wide)
opts_knit$set(concordance=TRUE)
opts_knit$set(unnamed.chunk.label = 'functions-chunk')
@

\chapter{R language: defining new ``words''}\label{chap:R:functions}

\begin{VF}
Computer Science is a science of abstraction---creating the right model for a problem and devising the appropriate mechanizable techniques to solve it.

\VA{Alfred V. Aho and Jeffrey D. Ullman}{Foundations of Computer Science}
\end{VF}

%\dictum[Alfred V. Aho, Jeffrey D. Ullman, \emph{Foundations of Computer Science}, Computer Science Press, 1992]{Computer Science is a science of abstraction---creating the right model for a problem and devising the appropriate mechanizable techniques to solve it.}\vskip2ex

\section{Aims of this chapter}

The aim of this chapter is to introduce some of the frequently used functions available in \pgrmname{R} including a sample of those used for statistical tests and model fitting. The \pgrmname{R} distribution includes both built-in functionality plus a set of recommended packages which one can count on always being available.

This chapter provides by necessity a very incomplete introduction to the capabilities of base R. This chapter is designed to give the reader only a quick introduction to base \R, as there are many good texts on the capabilities of \Rpgrm, going from the brief and concise books \citetitle{Beckerman2012} \autocite{Beckerman2012} and \citetitle{Allerhand2011} \autocite{Allerhand2011} at one extreme to the bulky and comprehensive \citetitle{Crawley2012} \autocite{Crawley2012} at the other. Books most useful as companions to the present book will be those somewhere in-between these two extremes. Three good examples with broad scope are \citetitle{Dalgaard2008} \autocite{Dalgaard2008}, \citetitle{Everitt2009} \autocite{Everitt2009} and \citetitle{??} \autocite{??}. Furthermore, many of base \R's functions are specific to different statistical procedures, maths and calculus, that transcend the description of \langname{R} as a programming language. The use of \pgrmname{R} for the analysis of different kinds of data and using different methods is covered by a vast bibliography, to which we provide some pointers in chapter \ref{chap:R:readings} on page \pageref{chap:R:readings}.

\section{Loading data}
\index{data!loading data sets}
To start with, we need some data to run the examples. Here we use \code{cars}, a data set included in base R. How to read or import ``foreign'' data is discussed in R's documentation in \emph{R Data Import/Export}, and in this book, in Chapter \ref{chap:R:data} starting on page \pageref{chap:R:data}. In general \Rfunction{data()} is used load R objects saved in a file format used by R. Text files con be read with functions \Rfunction{scan()}, \Rfunction{read.table()}, \Rfunction{read.csv()} and their variants. It is also possible to `import' data saved in files of \textit{foreign} formats, defined by other programs. Packages such as 'foreign', 'readr', 'readxl', 'RNetCDF', 'jsonlite', etc.\ allow importing data from other statistic and data analysis applications and from standard data exchange formats. It is also good to keep in mind that in R urls are accepted as arguments to the \code{file} argument (see Chapter \ref{chap:R:data} starting on page \pageref{chap:R:data} for details and examples on how to import data from different ``foreign'' formats and sources).

In the examples of the present chapter we use data included in R, as R objects, which can be loaded with function \code{data}. \code{cars} is a data frame.

<<data-1>>=
data(cars)
@

\section{Looking at data}
\index{data!exploring at the console}
There are several functions in \langname{R} that let us obtain different `views' into objects. Function \Rfunction{print()} is useful for small data sets, or objects. Especially in the case of large data frames, we need to explore them step by step. In the case of named components, we can obtain their names, with \Rfunction{names()}. If a data frame contains many rows of observations, \Rfunction{head()} and \Rfunction{tail()} allow us to easily restrict the number of rows printed. Functions \Rfunction{nrow()} and \Rfunction{ncol()} return the number of rows and columns in the data frame (but are not applicable to lists). As earlier mentioned, \Rfunction{str()}, outputs is abbreviated but in a way that preserves the structure of the object.
<<exploring-dfs-1>>=
class(cars)
nrow(cars)
ncol(cars)
names(cars)
head(cars)
tail(cars)
str(cars)
@

\begin{playground}
Look up the help pages for \Rfunction{head()} and \Rfunction{tail()}, and edit the code above to print only the first line, or only the last line of \code{cars}, respectively. As a second exercise print the 25 topmost rows of \code{cars}.
\end{playground}

Data frames consist in columns of equal length (see Chapter \ref{chap:R:as:calc}, section \ref{sec:R:data:frames} on page \pageref{sec:R:data:frames} for details). The different columns of a data frame can contain data of different modes (e.g.\ numeric, factor and/or character).

To explore the mode of the columns of \code{cars}, we can use an \emph{apply} function. In the present case, we want to apply function \code{mode()} to each column of the data frame \code{cars}.

<<exploring-dfs-2>>=
sapply(cars, mode)
@

The statement above returns a vector of character strings, with the mode of each column. Each element of the vector is named according to the name of the corresponding ``column'' in the data frame. For this same statement to be used with any other data frame or list, we need only to substitute the name of the object, the second argument, to the one of current interest.

\begin{playground}
Data set \code{airquality} contains data from air quality measurements in New York, and, being included in the \Rpgrm distribution, can be loaded with \code{data(airquality)}. Load it, and repeat the steps above, to learn what variables are included, their modes, the number of rows, etc.
\end{playground}

There is in \Rpgrm a function called \Rfunction{summary()}, which can be used to obtain a suitable summary from objects of most classes. We can also use \Rfunction{sapply()} or \Rfunction{lapply()} to apply any suitable function to individual columns. See section \ref{sec:data:apply} on page \pageref{sec:data:apply} for details about R's \emph{apply} functions.
<<exploring-dfs-3>>=
summary(cars)
sapply(cars, range)
@

\begin{playground}
Obtain the summary of \code{airquality} with function \Rfunction{summary()}, but in addition, write code with an \emph{apply} function to count the number of non-missing values in each column.
\end{playground}

\section{Plotting}
\index{plots!base R graphics}
The base \langname{R}'s generic function \code{plot()} can be used to plot different data. It is a generic function that has suitable methods for different kinds of objects (see section \ref{sec:script:objects:classes:methods} on page \pageref{sec:script:objects:classes:methods} for a brief introduction to objects, classes and methods). In this section we only very briefly demonstrate the use of the most common base \langname{R}'s graphics functions. They are well described in the book \citetitle{Murrell2011} \autocite{Murrell2011}. We will not describe either the Trellis and Lattice approach to plotting \autocite{Sarkar2008}. We describe in detail the use of the grammar of graphics and plotting with package \ggplot in Chapter \ref{chap:R:plotting} from page \pageref{chap:R:plotting} onwards.

<<plot-2>>=
plot(dist ~ speed, data = cars)
@

\section{Fitting linear models}
\index{models!linear}
\index{linear models}
\index{LM|see{linear models}}
One important thing to remember is that model `formulas' are used in different contexts: plotting, fitting of models, and tests like $t$-test. The basic syntax is rather consistently followed, although there are some exceptions.

\subsection{Regression}
\index{linear regression}
The R function \Rfunction{lm()} is used next to fit linear models. If the explanatory variable is continuous, the fit is a regression. In the example below, \code{speed} is a numeric variable (floating point in this case). In the ANOVA table calculated for the model fit, in this case a linear regression, we can see that the term for \code{speed} has only one degree of freedom (df) for the denominator.

We first fit the model and save the output as \code{fm1} (A name I invented to remind myself that this is the first fitted-model in this chapter.%
\label{xmpl:fun:lm:fm1}

<<models-1>>=
fm1 <- lm(dist ~ speed, data=cars)
@

The next step is diagnosis of the fit. Are assumptions of the linear model procedure used reasonably fulfilled? In R it is most common to use plots to this end. We show here only one of the four plots normally produced. This quantile vs.\ quantile plot allows to assess how much the residuals deviate from being normally distributed.

<<models-1a>>=
plot(fm1, which = 2)
@

In the case of a regression, calling \Rfunction{summary()} with the fitted model object as argument is most useful as it provides a table of coefficient estimates and their errors. \Rfunction{anova()} applied to the same fitted object, returns the ANOVA table.

<<models-1b>>=
summary(fm1) # we inspect the results from the fit
anova(fm1) # we calculate an ANOVA
@

Let's look at each argument separately: \verb|dist ~ speed| is the specification of the model to be fitted. The intercept is always implicitly included. To `remove' this implicit intercept from the earlier model we can use \verb|dist ~ speed - 1|. In what follows we fit a straight line through the origin ($x = 0$, $y = 0$).

<<models-2>>=
fm2 <- lm(dist ~ speed - 1, data=cars)
plot(fm2, which = 2)
summary(fm2)
anova(fm2)
@

We now we fit a second degree polynomial.

<<models-3>>=
fm3 <- lm(dist ~ speed + I(speed^2), data = cars) # we fit a model, and then save the result
plot(fm3, which = 3) # we produce diagnosis plots
summary(fm3) # we inspect the results from the fit
anova(fm3) # we calculate an ANOVA
@

The ``same'' fit using an orthogonal polynomial. Higher degrees can be obtained by supplying as second argument to \code{poly()} a different positive integer value.

<<models-3a>>=
fm3a <- lm(dist ~ poly(speed, 2), data=cars) # we fit a model, and then save the result
plot(fm3a, which = 3) # we produce diagnosis plots
summary(fm3a) # we inspect the results from the fit
anova(fm3a) # we calculate an ANOVA
@

We can also compare two models, to test whether one of models describes the data better than the other.

<<models-4>>=
anova(fm2, fm1)
@

Or three or more models. But be careful, as the order of the arguments matters.

<<models-5>>=
anova(fm2, fm1, fm3, fm3a)
@

We can use different criteria to choose the best model: significance based on $P$-values or information criteria (AIC, BIC). AIC and BIC penalize the resulting `goodness' based on the number of parameters in the fitted model. In the case of AIC and BIC, a smaller value is better, and values returned can be either positive or negative, in which case more negative is better.

<<>>=
BIC(fm2, fm1, fm3, fm3a)
AIC(fm2, fm1, fm3, fm3a)
@

One can see above that these three criteria not necessarily agree on which is the model to be chosen.

\begin{description}
\item[anova] \code{fm1}
\item[BIC] \code{fm1}
\item[AIC] \code{fm3}
\end{description}

\subsection{Analysis of variance, ANOVA}\label{sec:anova}
\index{analysis of variance}
\index{ANOVA|see{analysis of variance}}
We use as the \code{InsectSpray} data set, giving insect counts in plots sprayed with different insecticides. In these data \code{spray} is a factor with six levels.%
\label{xmpl:fun:lm:fm4}

<<models-6>>=
fm4 <- lm(count ~ spray, data = InsectSprays)
@

<<model-6a>>=
plot(fm4, which = 2)
@

<<model-6b>>=
anova(fm4)
@

\subsection{Analysis of covariance, ANCOVA}
\index{analysis of covariance}
\index{ANCOVA|see{analysis of covariance}}

When a linear model includes both explanatory factors and continuous explanatory variables, we say that analysis of covariance (ANCOVA) is used. The formula syntax is the same for all linear models, what determines the type of analysis is the nature of the explanatory variable(s). Conceptually a factor (an unordered categorical variable) is very different from a continuous variable.

\section{Generalized linear models}
\index{generalized linear models}
\index{GLM|see{generalized linear models}}

Linear models make the assumption of normally distributed residuals. Generalized linear models, fitted with function \Rfunction{glm()} are more flexible, and allow the assumed distribution to be selected as well as the link function.
For the analysis of the \code{InsectSpray} data set, above (section \ref{sec:anova} on page \pageref{sec:anova}) the Normal distribution is not a good approximation as count data deviates from it. This was visible in the quantile--quantile plot above.

For count data GLMs provide a better alternative. In the example below we fit the same model as above, but we assume a quasi-Poisson distribution instead of the Normal.

<<model-10>>=
fm10 <- glm(count ~ spray, data = InsectSprays, family = quasipoisson)
plot(fm10, which = 2)
anova(fm10, test = "F")
@

<<eval=eval_diag, include=eval_diag, echo=eval_diag, cache=FALSE>>=
knitter_diag()
R_diag()
other_diag()
@
